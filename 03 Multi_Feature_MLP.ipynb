{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Urban Sounds Classification using Deep Learning\n",
    "\n",
    "## Udacity-MLND\n",
    "\n",
    "### Multiple_Feature_MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "#importing Audio Visualisation Libraries\n",
    "from librosa import display\n",
    "import librosa\n",
    "#Getting the csv as dataframe using pandas\n",
    "data=pd.read_csv(\"UrbanSound8K/metadata/UrbanSound8K.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slice_file_name</th>\n",
       "      <th>fsID</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>salience</th>\n",
       "      <th>fold</th>\n",
       "      <th>classID</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100032-3-0-0.wav</td>\n",
       "      <td>100032</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.317551</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>dog_bark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100263-2-0-117.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>58.5</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100263-2-0-121.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>60.5</td>\n",
       "      <td>64.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100263-2-0-126.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>63.0</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100263-2-0-137.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>68.5</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      slice_file_name    fsID  start        end  salience  fold  classID  \\\n",
       "0    100032-3-0-0.wav  100032    0.0   0.317551         1     5        3   \n",
       "1  100263-2-0-117.wav  100263   58.5  62.500000         1     5        2   \n",
       "2  100263-2-0-121.wav  100263   60.5  64.500000         1     5        2   \n",
       "3  100263-2-0-126.wav  100263   63.0  67.000000         1     5        2   \n",
       "4  100263-2-0-137.wav  100263   68.5  72.500000         1     5        2   \n",
       "\n",
       "              class  \n",
       "0          dog_bark  \n",
       "1  children_playing  \n",
       "2  children_playing  \n",
       "3  children_playing  \n",
       "4  children_playing  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#displaying the structure of the CSV\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▌                                                                             | 67/8732 [00:30<1:06:07,  2.18it/s]C:\\Anaconda3\\lib\\site-packages\\librosa\\core\\pitch.py:146: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  warnings.warn('Trying to estimate tuning from empty frequency set.')\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 8732/8732 [1:04:30<00:00,  2.83it/s]\n"
     ]
    }
   ],
   "source": [
    "#preprocessing using all features set\n",
    "x_train=[]\n",
    "x_test=[]\n",
    "y_train=[]\n",
    "y_test=[]\n",
    "path=\"UrbanSound8K/audio/fold\"\n",
    "for i in tqdm(range(len(data))):\n",
    "    fold_no=str(data.iloc[i][\"fold\"])\n",
    "    file=data.iloc[i][\"slice_file_name\"]\n",
    "    label=data.iloc[i][\"classID\"]\n",
    "    filename=path+fold_no+\"/\"+file\n",
    "    y,sr=librosa.load(filename)\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y, sr, n_mfcc=40).T,axis=0)\n",
    "    melspectrogram = np.mean(librosa.feature.melspectrogram(y=y, sr=sr, n_mels=40,fmax=8000).T,axis=0)\n",
    "    chroma_stft=np.mean(librosa.feature.chroma_stft(y=y, sr=sr,n_chroma=40).T,axis=0)\n",
    "    chroma_cq = np.mean(librosa.feature.chroma_cqt(y=y, sr=sr,n_chroma=40).T,axis=0)\n",
    "    chroma_cens = np.mean(librosa.feature.chroma_cens(y=y, sr=sr,n_chroma=40).T,axis=0)\n",
    "    features=np.reshape(np.vstack((mfccs,melspectrogram,chroma_stft,chroma_cq,chroma_cens)),(40,5))\n",
    "    if(fold_no!='10'):\n",
    "      x_train.append(features)\n",
    "      y_train.append(label)\n",
    "    else:\n",
    "      x_test.append(features)\n",
    "      y_test.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7895, 40, 5), (837, 40, 5), (7895,), (837,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#converting the lists into numpy arrays\n",
    "x_train=np.array(x_train)\n",
    "x_test=np.array(x_test)\n",
    "y_train=np.array(y_train)\n",
    "y_test=np.array(y_test)\n",
    "x_train.shape,x_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7895, 200), (837, 200))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reshaping into 2d to save in csv format\n",
    "x_train_2d=np.reshape(x_train,(x_train.shape[0],x_train.shape[1]*x_train.shape[2]))\n",
    "x_test_2d=np.reshape(x_test,(x_test.shape[0],x_test.shape[1]*x_test.shape[2]))\n",
    "x_train_2d.shape,x_test_2d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the data numpy arrays\n",
    "np.savetxt(\"train_data_multi.csv\", x_train_2d, delimiter=\",\")\n",
    "np.savetxt(\"test_data_multi.csv\",x_test_2d,delimiter=\",\")\n",
    "np.savetxt(\"train_labels_multi.csv\",y_train,delimiter=\",\")\n",
    "np.savetxt(\"test_labels_multi.csv\",y_test,delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting data from csv files into numpy arrays\n",
    "from numpy import genfromtxt\n",
    "x_train = genfromtxt('train_data_multi.csv', delimiter=',')\n",
    "y_train = genfromtxt('train_labels_multi.csv', delimiter=',')\n",
    "x_test = genfromtxt('test_data_multi.csv', delimiter=',')\n",
    "y_test = genfromtxt('test_labels_multi.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7895, 200), (837, 200), (7895,), (837,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shape\n",
    "x_train.shape,x_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((7895, 10), (837, 10))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#converting to one hot\n",
    "from keras.utils.np_utils import to_categorical\n",
    "y_train = to_categorical(y_train, num_classes=10)\n",
    "y_test = to_categorical(y_test, num_classes=10)\n",
    "y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7895, 200), (837, 200))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shapes\n",
    "x_train.shape,x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense,Dropout,Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forming model\n",
    "model=Sequential()\n",
    "#building the model\n",
    "model.add(Dense(units=256,activation='relu',input_dim=200))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=256,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=256,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0831 20:59:28.733877 16832 deprecation_wrapper.py:119] From C:\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0831 20:59:28.775738 16832 deprecation_wrapper.py:119] From C:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#compiling\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7895 samples, validate on 837 samples\n",
      "Epoch 1/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.5773 - acc: 0.860 - ETA: 1s - loss: 0.5725 - acc: 0.822 - ETA: 1s - loss: 0.5971 - acc: 0.803 - ETA: 0s - loss: 0.6054 - acc: 0.800 - ETA: 0s - loss: 0.6068 - acc: 0.802 - ETA: 0s - loss: 0.6165 - acc: 0.804 - ETA: 0s - loss: 0.6098 - acc: 0.804 - ETA: 0s - loss: 0.6170 - acc: 0.801 - ETA: 0s - loss: 0.6124 - acc: 0.804 - ETA: 0s - loss: 0.6042 - acc: 0.806 - ETA: 0s - loss: 0.6085 - acc: 0.805 - ETA: 0s - loss: 0.6086 - acc: 0.804 - ETA: 0s - loss: 0.6107 - acc: 0.803 - ETA: 0s - loss: 0.6173 - acc: 0.801 - ETA: 0s - loss: 0.6159 - acc: 0.800 - ETA: 0s - loss: 0.6180 - acc: 0.800 - ETA: 0s - loss: 0.6159 - acc: 0.801 - ETA: 0s - loss: 0.6128 - acc: 0.802 - ETA: 0s - loss: 0.6137 - acc: 0.802 - ETA: 0s - loss: 0.6096 - acc: 0.802 - ETA: 0s - loss: 0.6125 - acc: 0.801 - 1s 147us/step - loss: 0.6178 - acc: 0.8000 - val_loss: 1.2023 - val_acc: 0.6213\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.20225, saving model to Saved_models/multi_mlp.hdf5\n",
      "Epoch 2/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.9953 - acc: 0.720 - ETA: 1s - loss: 0.5994 - acc: 0.797 - ETA: 1s - loss: 0.6396 - acc: 0.790 - ETA: 0s - loss: 0.6159 - acc: 0.801 - ETA: 0s - loss: 0.6173 - acc: 0.800 - ETA: 0s - loss: 0.6082 - acc: 0.803 - ETA: 0s - loss: 0.6202 - acc: 0.797 - ETA: 0s - loss: 0.6231 - acc: 0.800 - ETA: 0s - loss: 0.6259 - acc: 0.799 - ETA: 0s - loss: 0.6316 - acc: 0.797 - ETA: 0s - loss: 0.6324 - acc: 0.795 - ETA: 0s - loss: 0.6310 - acc: 0.795 - ETA: 0s - loss: 0.6302 - acc: 0.796 - ETA: 0s - loss: 0.6325 - acc: 0.794 - ETA: 0s - loss: 0.6385 - acc: 0.794 - ETA: 0s - loss: 0.6391 - acc: 0.795 - ETA: 0s - loss: 0.6393 - acc: 0.795 - ETA: 0s - loss: 0.6331 - acc: 0.796 - ETA: 0s - loss: 0.6329 - acc: 0.796 - ETA: 0s - loss: 0.6322 - acc: 0.797 - ETA: 0s - loss: 0.6304 - acc: 0.797 - 1s 147us/step - loss: 0.6288 - acc: 0.7976 - val_loss: 1.1714 - val_acc: 0.6428\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.20225 to 1.17137, saving model to Saved_models/multi_mlp.hdf5\n",
      "Epoch 3/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 1.0176 - acc: 0.700 - ETA: 1s - loss: 0.7365 - acc: 0.762 - ETA: 1s - loss: 0.6525 - acc: 0.785 - ETA: 1s - loss: 0.6401 - acc: 0.797 - ETA: 0s - loss: 0.6186 - acc: 0.802 - ETA: 0s - loss: 0.6234 - acc: 0.798 - ETA: 0s - loss: 0.6233 - acc: 0.803 - ETA: 0s - loss: 0.6285 - acc: 0.798 - ETA: 0s - loss: 0.6243 - acc: 0.797 - ETA: 0s - loss: 0.6188 - acc: 0.802 - ETA: 0s - loss: 0.6180 - acc: 0.804 - ETA: 0s - loss: 0.6091 - acc: 0.804 - ETA: 0s - loss: 0.6091 - acc: 0.803 - ETA: 0s - loss: 0.6143 - acc: 0.799 - ETA: 0s - loss: 0.6155 - acc: 0.800 - ETA: 0s - loss: 0.6172 - acc: 0.799 - ETA: 0s - loss: 0.6162 - acc: 0.800 - ETA: 0s - loss: 0.6147 - acc: 0.801 - ETA: 0s - loss: 0.6135 - acc: 0.801 - ETA: 0s - loss: 0.6127 - acc: 0.801 - ETA: 0s - loss: 0.6114 - acc: 0.803 - ETA: 0s - loss: 0.6131 - acc: 0.801 - 1s 148us/step - loss: 0.6110 - acc: 0.8024 - val_loss: 1.2418 - val_acc: 0.6547\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.17137\n",
      "Epoch 4/50\n",
      "7895/7895 [==============================] - ETA: 2s - loss: 0.5670 - acc: 0.840 - ETA: 1s - loss: 0.6048 - acc: 0.806 - ETA: 0s - loss: 0.5829 - acc: 0.820 - ETA: 0s - loss: 0.6337 - acc: 0.800 - ETA: 0s - loss: 0.6234 - acc: 0.801 - ETA: 0s - loss: 0.6220 - acc: 0.803 - ETA: 0s - loss: 0.6227 - acc: 0.800 - ETA: 0s - loss: 0.6118 - acc: 0.804 - ETA: 0s - loss: 0.6119 - acc: 0.808 - ETA: 0s - loss: 0.6115 - acc: 0.808 - ETA: 0s - loss: 0.6057 - acc: 0.808 - ETA: 0s - loss: 0.6048 - acc: 0.809 - ETA: 0s - loss: 0.6009 - acc: 0.811 - ETA: 0s - loss: 0.6035 - acc: 0.810 - ETA: 0s - loss: 0.6077 - acc: 0.810 - ETA: 0s - loss: 0.6039 - acc: 0.811 - ETA: 0s - loss: 0.6043 - acc: 0.811 - ETA: 0s - loss: 0.6074 - acc: 0.811 - ETA: 0s - loss: 0.6042 - acc: 0.811 - ETA: 0s - loss: 0.6081 - acc: 0.807 - 1s 141us/step - loss: 0.6078 - acc: 0.8079 - val_loss: 1.2128 - val_acc: 0.6213\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.17137\n",
      "Epoch 5/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.5053 - acc: 0.840 - ETA: 1s - loss: 0.5032 - acc: 0.826 - ETA: 1s - loss: 0.5596 - acc: 0.811 - ETA: 0s - loss: 0.5763 - acc: 0.807 - ETA: 0s - loss: 0.6106 - acc: 0.804 - ETA: 0s - loss: 0.6164 - acc: 0.802 - ETA: 0s - loss: 0.6070 - acc: 0.802 - ETA: 0s - loss: 0.6070 - acc: 0.800 - ETA: 0s - loss: 0.6016 - acc: 0.802 - ETA: 0s - loss: 0.6062 - acc: 0.802 - ETA: 0s - loss: 0.6036 - acc: 0.803 - ETA: 0s - loss: 0.5941 - acc: 0.806 - ETA: 0s - loss: 0.6031 - acc: 0.804 - ETA: 0s - loss: 0.6062 - acc: 0.804 - ETA: 0s - loss: 0.6106 - acc: 0.802 - ETA: 0s - loss: 0.6053 - acc: 0.804 - ETA: 0s - loss: 0.6040 - acc: 0.805 - ETA: 0s - loss: 0.6078 - acc: 0.803 - ETA: 0s - loss: 0.6085 - acc: 0.803 - ETA: 0s - loss: 0.6040 - acc: 0.804 - ETA: 0s - loss: 0.6012 - acc: 0.804 - 1s 144us/step - loss: 0.6000 - acc: 0.8058 - val_loss: 1.2612 - val_acc: 0.5950\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.17137\n",
      "Epoch 6/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.6763 - acc: 0.840 - ETA: 1s - loss: 0.6167 - acc: 0.822 - ETA: 0s - loss: 0.6278 - acc: 0.809 - ETA: 0s - loss: 0.6237 - acc: 0.800 - ETA: 0s - loss: 0.6219 - acc: 0.807 - ETA: 0s - loss: 0.6148 - acc: 0.808 - ETA: 0s - loss: 0.5979 - acc: 0.811 - ETA: 0s - loss: 0.5807 - acc: 0.818 - ETA: 0s - loss: 0.5791 - acc: 0.815 - ETA: 0s - loss: 0.5784 - acc: 0.815 - ETA: 0s - loss: 0.5825 - acc: 0.813 - ETA: 0s - loss: 0.5876 - acc: 0.813 - ETA: 0s - loss: 0.5918 - acc: 0.809 - ETA: 0s - loss: 0.5912 - acc: 0.809 - ETA: 0s - loss: 0.5920 - acc: 0.807 - ETA: 0s - loss: 0.5956 - acc: 0.807 - ETA: 0s - loss: 0.5924 - acc: 0.808 - ETA: 0s - loss: 0.5901 - acc: 0.809 - ETA: 0s - loss: 0.5910 - acc: 0.810 - ETA: 0s - loss: 0.5908 - acc: 0.809 - ETA: 0s - loss: 0.5892 - acc: 0.809 - ETA: 0s - loss: 0.5860 - acc: 0.810 - ETA: 0s - loss: 0.5903 - acc: 0.810 - 1s 159us/step - loss: 0.5902 - acc: 0.8118 - val_loss: 1.2142 - val_acc: 0.6272\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.17137\n",
      "Epoch 7/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.6329 - acc: 0.760 - ETA: 1s - loss: 0.6467 - acc: 0.793 - ETA: 1s - loss: 0.6339 - acc: 0.800 - ETA: 0s - loss: 0.6514 - acc: 0.798 - ETA: 0s - loss: 0.6298 - acc: 0.807 - ETA: 0s - loss: 0.6139 - acc: 0.810 - ETA: 0s - loss: 0.5971 - acc: 0.813 - ETA: 0s - loss: 0.6047 - acc: 0.810 - ETA: 0s - loss: 0.5891 - acc: 0.813 - ETA: 0s - loss: 0.5849 - acc: 0.813 - ETA: 0s - loss: 0.5889 - acc: 0.812 - ETA: 0s - loss: 0.5871 - acc: 0.811 - ETA: 0s - loss: 0.5862 - acc: 0.813 - ETA: 0s - loss: 0.5897 - acc: 0.812 - ETA: 0s - loss: 0.5910 - acc: 0.811 - ETA: 0s - loss: 0.5916 - acc: 0.812 - ETA: 0s - loss: 0.5914 - acc: 0.812 - ETA: 0s - loss: 0.5884 - acc: 0.813 - ETA: 0s - loss: 0.5870 - acc: 0.813 - ETA: 0s - loss: 0.5874 - acc: 0.812 - ETA: 0s - loss: 0.5873 - acc: 0.811 - ETA: 0s - loss: 0.5889 - acc: 0.811 - 1s 151us/step - loss: 0.5879 - acc: 0.8119 - val_loss: 1.2350 - val_acc: 0.6213\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.17137\n",
      "Epoch 8/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.3937 - acc: 0.860 - ETA: 1s - loss: 0.5317 - acc: 0.847 - ETA: 1s - loss: 0.5357 - acc: 0.834 - ETA: 1s - loss: 0.5481 - acc: 0.826 - ETA: 0s - loss: 0.5309 - acc: 0.826 - ETA: 0s - loss: 0.5446 - acc: 0.821 - ETA: 0s - loss: 0.5529 - acc: 0.820 - ETA: 0s - loss: 0.5608 - acc: 0.819 - ETA: 0s - loss: 0.5598 - acc: 0.821 - ETA: 0s - loss: 0.5689 - acc: 0.819 - ETA: 0s - loss: 0.5605 - acc: 0.818 - ETA: 0s - loss: 0.5603 - acc: 0.820 - ETA: 0s - loss: 0.5620 - acc: 0.818 - ETA: 0s - loss: 0.5551 - acc: 0.817 - ETA: 0s - loss: 0.5597 - acc: 0.818 - ETA: 0s - loss: 0.5563 - acc: 0.817 - ETA: 0s - loss: 0.5603 - acc: 0.816 - ETA: 0s - loss: 0.5620 - acc: 0.815 - ETA: 0s - loss: 0.5582 - acc: 0.816 - ETA: 0s - loss: 0.5608 - acc: 0.816 - ETA: 0s - loss: 0.5615 - acc: 0.815 - ETA: 0s - loss: 0.5628 - acc: 0.815 - 1s 155us/step - loss: 0.5604 - acc: 0.8162 - val_loss: 1.2371 - val_acc: 0.6308\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.17137\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7895/7895 [==============================] - ETA: 1s - loss: 0.5462 - acc: 0.840 - ETA: 1s - loss: 0.6043 - acc: 0.802 - ETA: 1s - loss: 0.6509 - acc: 0.797 - ETA: 0s - loss: 0.6035 - acc: 0.810 - ETA: 0s - loss: 0.5831 - acc: 0.812 - ETA: 0s - loss: 0.5705 - acc: 0.813 - ETA: 0s - loss: 0.5699 - acc: 0.813 - ETA: 0s - loss: 0.5601 - acc: 0.816 - ETA: 0s - loss: 0.5640 - acc: 0.814 - ETA: 0s - loss: 0.5771 - acc: 0.811 - ETA: 0s - loss: 0.5819 - acc: 0.807 - ETA: 0s - loss: 0.5837 - acc: 0.808 - ETA: 0s - loss: 0.5877 - acc: 0.808 - ETA: 0s - loss: 0.5881 - acc: 0.807 - ETA: 0s - loss: 0.5881 - acc: 0.809 - ETA: 0s - loss: 0.5856 - acc: 0.812 - ETA: 0s - loss: 0.5764 - acc: 0.814 - ETA: 0s - loss: 0.5811 - acc: 0.813 - ETA: 0s - loss: 0.5825 - acc: 0.812 - ETA: 0s - loss: 0.5796 - acc: 0.813 - ETA: 0s - loss: 0.5836 - acc: 0.813 - ETA: 0s - loss: 0.5813 - acc: 0.813 - ETA: 0s - loss: 0.5834 - acc: 0.812 - 1s 159us/step - loss: 0.5862 - acc: 0.8115 - val_loss: 1.2440 - val_acc: 0.6260\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.17137\n",
      "Epoch 10/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.4803 - acc: 0.820 - ETA: 1s - loss: 0.5091 - acc: 0.835 - ETA: 1s - loss: 0.5286 - acc: 0.822 - ETA: 1s - loss: 0.5177 - acc: 0.828 - ETA: 1s - loss: 0.5221 - acc: 0.824 - ETA: 0s - loss: 0.5417 - acc: 0.822 - ETA: 0s - loss: 0.5458 - acc: 0.823 - ETA: 0s - loss: 0.5529 - acc: 0.818 - ETA: 0s - loss: 0.5553 - acc: 0.821 - ETA: 0s - loss: 0.5579 - acc: 0.819 - ETA: 0s - loss: 0.5628 - acc: 0.818 - ETA: 0s - loss: 0.5723 - acc: 0.815 - ETA: 0s - loss: 0.5784 - acc: 0.810 - ETA: 0s - loss: 0.5727 - acc: 0.812 - ETA: 0s - loss: 0.5757 - acc: 0.811 - ETA: 0s - loss: 0.5779 - acc: 0.812 - ETA: 0s - loss: 0.5790 - acc: 0.809 - ETA: 0s - loss: 0.5759 - acc: 0.811 - ETA: 0s - loss: 0.5767 - acc: 0.811 - ETA: 0s - loss: 0.5736 - acc: 0.812 - ETA: 0s - loss: 0.5751 - acc: 0.811 - ETA: 0s - loss: 0.5766 - acc: 0.811 - ETA: 0s - loss: 0.5761 - acc: 0.811 - ETA: 0s - loss: 0.5781 - acc: 0.811 - 1s 165us/step - loss: 0.5766 - acc: 0.8113 - val_loss: 1.2555 - val_acc: 0.6392\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.17137\n",
      "Epoch 11/50\n",
      "7895/7895 [==============================] - ETA: 3s - loss: 0.5741 - acc: 0.780 - ETA: 2s - loss: 0.6021 - acc: 0.790 - ETA: 1s - loss: 0.6294 - acc: 0.792 - ETA: 1s - loss: 0.5842 - acc: 0.810 - ETA: 1s - loss: 0.5751 - acc: 0.815 - ETA: 1s - loss: 0.5604 - acc: 0.820 - ETA: 1s - loss: 0.5393 - acc: 0.832 - ETA: 1s - loss: 0.5452 - acc: 0.828 - ETA: 1s - loss: 0.5462 - acc: 0.826 - ETA: 1s - loss: 0.5454 - acc: 0.828 - ETA: 0s - loss: 0.5494 - acc: 0.825 - ETA: 0s - loss: 0.5576 - acc: 0.820 - ETA: 0s - loss: 0.5601 - acc: 0.819 - ETA: 0s - loss: 0.5679 - acc: 0.818 - ETA: 0s - loss: 0.5618 - acc: 0.819 - ETA: 0s - loss: 0.5538 - acc: 0.823 - ETA: 0s - loss: 0.5510 - acc: 0.824 - ETA: 0s - loss: 0.5537 - acc: 0.823 - ETA: 0s - loss: 0.5484 - acc: 0.825 - ETA: 0s - loss: 0.5517 - acc: 0.824 - ETA: 0s - loss: 0.5478 - acc: 0.824 - ETA: 0s - loss: 0.5473 - acc: 0.825 - ETA: 0s - loss: 0.5395 - acc: 0.827 - ETA: 0s - loss: 0.5411 - acc: 0.826 - ETA: 0s - loss: 0.5419 - acc: 0.825 - ETA: 0s - loss: 0.5442 - acc: 0.825 - ETA: 0s - loss: 0.5502 - acc: 0.822 - ETA: 0s - loss: 0.5524 - acc: 0.822 - 2s 200us/step - loss: 0.5516 - acc: 0.8218 - val_loss: 1.1977 - val_acc: 0.6607\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.17137\n",
      "Epoch 12/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.8337 - acc: 0.720 - ETA: 1s - loss: 0.6527 - acc: 0.777 - ETA: 0s - loss: 0.6220 - acc: 0.788 - ETA: 0s - loss: 0.5961 - acc: 0.800 - ETA: 0s - loss: 0.5983 - acc: 0.798 - ETA: 0s - loss: 0.5910 - acc: 0.802 - ETA: 0s - loss: 0.5902 - acc: 0.802 - ETA: 0s - loss: 0.5930 - acc: 0.806 - ETA: 0s - loss: 0.5897 - acc: 0.810 - ETA: 0s - loss: 0.5895 - acc: 0.809 - ETA: 0s - loss: 0.5872 - acc: 0.810 - ETA: 0s - loss: 0.5852 - acc: 0.811 - ETA: 0s - loss: 0.5732 - acc: 0.815 - ETA: 0s - loss: 0.5708 - acc: 0.815 - ETA: 0s - loss: 0.5637 - acc: 0.819 - ETA: 0s - loss: 0.5598 - acc: 0.819 - ETA: 0s - loss: 0.5668 - acc: 0.817 - ETA: 0s - loss: 0.5731 - acc: 0.815 - ETA: 0s - loss: 0.5692 - acc: 0.816 - ETA: 0s - loss: 0.5670 - acc: 0.816 - ETA: 0s - loss: 0.5643 - acc: 0.818 - 1s 146us/step - loss: 0.5634 - acc: 0.8184 - val_loss: 1.1942 - val_acc: 0.6631\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.17137\n",
      "Epoch 13/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.6900 - acc: 0.820 - ETA: 1s - loss: 0.5770 - acc: 0.825 - ETA: 1s - loss: 0.5846 - acc: 0.822 - ETA: 1s - loss: 0.5544 - acc: 0.827 - ETA: 0s - loss: 0.5698 - acc: 0.825 - ETA: 0s - loss: 0.5627 - acc: 0.828 - ETA: 0s - loss: 0.5590 - acc: 0.826 - ETA: 0s - loss: 0.5509 - acc: 0.828 - ETA: 0s - loss: 0.5552 - acc: 0.826 - ETA: 0s - loss: 0.5587 - acc: 0.823 - ETA: 0s - loss: 0.5560 - acc: 0.823 - ETA: 0s - loss: 0.5592 - acc: 0.822 - ETA: 0s - loss: 0.5518 - acc: 0.823 - ETA: 0s - loss: 0.5511 - acc: 0.823 - ETA: 0s - loss: 0.5490 - acc: 0.823 - ETA: 0s - loss: 0.5444 - acc: 0.823 - ETA: 0s - loss: 0.5416 - acc: 0.825 - ETA: 0s - loss: 0.5506 - acc: 0.822 - ETA: 0s - loss: 0.5470 - acc: 0.824 - ETA: 0s - loss: 0.5433 - acc: 0.826 - ETA: 0s - loss: 0.5451 - acc: 0.825 - ETA: 0s - loss: 0.5429 - acc: 0.825 - 1s 151us/step - loss: 0.5390 - acc: 0.8265 - val_loss: 1.2366 - val_acc: 0.6655\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.17137\n",
      "Epoch 14/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.4299 - acc: 0.860 - ETA: 1s - loss: 0.4939 - acc: 0.837 - ETA: 1s - loss: 0.5197 - acc: 0.842 - ETA: 0s - loss: 0.5087 - acc: 0.841 - ETA: 0s - loss: 0.5165 - acc: 0.835 - ETA: 0s - loss: 0.5196 - acc: 0.835 - ETA: 0s - loss: 0.5224 - acc: 0.832 - ETA: 0s - loss: 0.5320 - acc: 0.829 - ETA: 0s - loss: 0.5295 - acc: 0.828 - ETA: 0s - loss: 0.5290 - acc: 0.829 - ETA: 0s - loss: 0.5323 - acc: 0.826 - ETA: 0s - loss: 0.5376 - acc: 0.823 - ETA: 0s - loss: 0.5387 - acc: 0.823 - ETA: 0s - loss: 0.5383 - acc: 0.823 - ETA: 0s - loss: 0.5351 - acc: 0.824 - ETA: 0s - loss: 0.5344 - acc: 0.827 - ETA: 0s - loss: 0.5361 - acc: 0.825 - ETA: 0s - loss: 0.5359 - acc: 0.826 - ETA: 0s - loss: 0.5371 - acc: 0.826 - ETA: 0s - loss: 0.5406 - acc: 0.824 - ETA: 0s - loss: 0.5368 - acc: 0.826 - ETA: 0s - loss: 0.5372 - acc: 0.827 - 1s 147us/step - loss: 0.5383 - acc: 0.8270 - val_loss: 1.1682 - val_acc: 0.6416\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.17137 to 1.16821, saving model to Saved_models/multi_mlp.hdf5\n",
      "Epoch 15/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.6848 - acc: 0.720 - ETA: 1s - loss: 0.5451 - acc: 0.807 - ETA: 1s - loss: 0.5612 - acc: 0.809 - ETA: 1s - loss: 0.5386 - acc: 0.820 - ETA: 0s - loss: 0.5104 - acc: 0.830 - ETA: 0s - loss: 0.4977 - acc: 0.835 - ETA: 0s - loss: 0.5030 - acc: 0.836 - ETA: 0s - loss: 0.4897 - acc: 0.841 - ETA: 0s - loss: 0.4972 - acc: 0.841 - ETA: 0s - loss: 0.5078 - acc: 0.836 - ETA: 0s - loss: 0.5140 - acc: 0.833 - ETA: 0s - loss: 0.5091 - acc: 0.836 - ETA: 0s - loss: 0.5143 - acc: 0.832 - ETA: 0s - loss: 0.5204 - acc: 0.831 - ETA: 0s - loss: 0.5175 - acc: 0.831 - ETA: 0s - loss: 0.5139 - acc: 0.832 - ETA: 0s - loss: 0.5173 - acc: 0.832 - ETA: 0s - loss: 0.5182 - acc: 0.831 - ETA: 0s - loss: 0.5186 - acc: 0.831 - ETA: 0s - loss: 0.5144 - acc: 0.832 - ETA: 0s - loss: 0.5160 - acc: 0.832 - ETA: 0s - loss: 0.5166 - acc: 0.831 - ETA: 0s - loss: 0.5229 - acc: 0.831 - 1s 157us/step - loss: 0.5254 - acc: 0.8307 - val_loss: 1.2516 - val_acc: 0.6499\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.16821\n",
      "Epoch 16/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7895/7895 [==============================] - ETA: 1s - loss: 0.5910 - acc: 0.840 - ETA: 0s - loss: 0.5345 - acc: 0.822 - ETA: 0s - loss: 0.5315 - acc: 0.827 - ETA: 0s - loss: 0.5564 - acc: 0.816 - ETA: 0s - loss: 0.5628 - acc: 0.813 - ETA: 0s - loss: 0.5551 - acc: 0.817 - ETA: 0s - loss: 0.5388 - acc: 0.822 - ETA: 0s - loss: 0.5331 - acc: 0.823 - ETA: 0s - loss: 0.5358 - acc: 0.821 - ETA: 0s - loss: 0.5431 - acc: 0.820 - ETA: 0s - loss: 0.5349 - acc: 0.822 - ETA: 0s - loss: 0.5336 - acc: 0.824 - ETA: 0s - loss: 0.5371 - acc: 0.826 - ETA: 0s - loss: 0.5391 - acc: 0.827 - ETA: 0s - loss: 0.5431 - acc: 0.827 - ETA: 0s - loss: 0.5376 - acc: 0.828 - ETA: 0s - loss: 0.5359 - acc: 0.829 - ETA: 0s - loss: 0.5381 - acc: 0.828 - ETA: 0s - loss: 0.5396 - acc: 0.828 - ETA: 0s - loss: 0.5377 - acc: 0.828 - ETA: 0s - loss: 0.5374 - acc: 0.828 - ETA: 0s - loss: 0.5339 - acc: 0.829 - 1s 150us/step - loss: 0.5331 - acc: 0.8301 - val_loss: 1.2079 - val_acc: 0.6595\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.16821\n",
      "Epoch 17/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.4345 - acc: 0.880 - ETA: 1s - loss: 0.4758 - acc: 0.837 - ETA: 1s - loss: 0.4934 - acc: 0.826 - ETA: 1s - loss: 0.4779 - acc: 0.837 - ETA: 1s - loss: 0.5031 - acc: 0.835 - ETA: 0s - loss: 0.5087 - acc: 0.834 - ETA: 0s - loss: 0.5091 - acc: 0.833 - ETA: 0s - loss: 0.5119 - acc: 0.834 - ETA: 0s - loss: 0.5157 - acc: 0.833 - ETA: 0s - loss: 0.5089 - acc: 0.837 - ETA: 0s - loss: 0.5006 - acc: 0.839 - ETA: 0s - loss: 0.5088 - acc: 0.835 - ETA: 0s - loss: 0.5052 - acc: 0.837 - ETA: 0s - loss: 0.5045 - acc: 0.837 - ETA: 0s - loss: 0.4968 - acc: 0.839 - ETA: 0s - loss: 0.4933 - acc: 0.839 - ETA: 0s - loss: 0.4934 - acc: 0.839 - ETA: 0s - loss: 0.4968 - acc: 0.839 - ETA: 0s - loss: 0.5044 - acc: 0.838 - ETA: 0s - loss: 0.5054 - acc: 0.838 - ETA: 0s - loss: 0.5083 - acc: 0.839 - ETA: 0s - loss: 0.5087 - acc: 0.838 - 1s 151us/step - loss: 0.5056 - acc: 0.8393 - val_loss: 1.2300 - val_acc: 0.6392\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.16821\n",
      "Epoch 18/50\n",
      "7895/7895 [==============================] - ETA: 0s - loss: 0.6717 - acc: 0.760 - ETA: 1s - loss: 0.5961 - acc: 0.815 - ETA: 1s - loss: 0.5986 - acc: 0.817 - ETA: 0s - loss: 0.5932 - acc: 0.811 - ETA: 0s - loss: 0.5559 - acc: 0.825 - ETA: 0s - loss: 0.5490 - acc: 0.832 - ETA: 0s - loss: 0.5597 - acc: 0.826 - ETA: 0s - loss: 0.5493 - acc: 0.827 - ETA: 0s - loss: 0.5564 - acc: 0.823 - ETA: 0s - loss: 0.5631 - acc: 0.820 - ETA: 0s - loss: 0.5533 - acc: 0.827 - ETA: 0s - loss: 0.5566 - acc: 0.825 - ETA: 0s - loss: 0.5506 - acc: 0.827 - ETA: 0s - loss: 0.5486 - acc: 0.827 - ETA: 0s - loss: 0.5428 - acc: 0.828 - ETA: 0s - loss: 0.5350 - acc: 0.830 - ETA: 0s - loss: 0.5385 - acc: 0.830 - ETA: 0s - loss: 0.5326 - acc: 0.832 - ETA: 0s - loss: 0.5307 - acc: 0.833 - ETA: 0s - loss: 0.5280 - acc: 0.833 - ETA: 0s - loss: 0.5233 - acc: 0.834 - 1s 146us/step - loss: 0.5253 - acc: 0.8337 - val_loss: 1.2412 - val_acc: 0.6452\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.16821\n",
      "Epoch 19/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.6163 - acc: 0.800 - ETA: 1s - loss: 0.5466 - acc: 0.830 - ETA: 1s - loss: 0.5333 - acc: 0.838 - ETA: 1s - loss: 0.5471 - acc: 0.833 - ETA: 0s - loss: 0.5312 - acc: 0.834 - ETA: 0s - loss: 0.5209 - acc: 0.838 - ETA: 0s - loss: 0.5081 - acc: 0.842 - ETA: 0s - loss: 0.5195 - acc: 0.839 - ETA: 0s - loss: 0.5229 - acc: 0.838 - ETA: 0s - loss: 0.5229 - acc: 0.836 - ETA: 0s - loss: 0.5135 - acc: 0.839 - ETA: 0s - loss: 0.5236 - acc: 0.839 - ETA: 0s - loss: 0.5231 - acc: 0.838 - ETA: 0s - loss: 0.5217 - acc: 0.839 - ETA: 0s - loss: 0.5260 - acc: 0.837 - ETA: 0s - loss: 0.5244 - acc: 0.837 - ETA: 0s - loss: 0.5197 - acc: 0.838 - ETA: 0s - loss: 0.5147 - acc: 0.839 - ETA: 0s - loss: 0.5130 - acc: 0.839 - ETA: 0s - loss: 0.5106 - acc: 0.840 - ETA: 0s - loss: 0.5117 - acc: 0.840 - ETA: 0s - loss: 0.5153 - acc: 0.840 - 1s 150us/step - loss: 0.5148 - acc: 0.8402 - val_loss: 1.2483 - val_acc: 0.6213\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.16821\n",
      "Epoch 20/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.2976 - acc: 0.940 - ETA: 1s - loss: 0.5058 - acc: 0.846 - ETA: 1s - loss: 0.4890 - acc: 0.848 - ETA: 0s - loss: 0.4792 - acc: 0.850 - ETA: 0s - loss: 0.4591 - acc: 0.853 - ETA: 0s - loss: 0.4722 - acc: 0.851 - ETA: 0s - loss: 0.4605 - acc: 0.853 - ETA: 0s - loss: 0.4704 - acc: 0.849 - ETA: 0s - loss: 0.4808 - acc: 0.848 - ETA: 0s - loss: 0.4772 - acc: 0.849 - ETA: 0s - loss: 0.4712 - acc: 0.851 - ETA: 0s - loss: 0.4727 - acc: 0.849 - ETA: 0s - loss: 0.4826 - acc: 0.847 - ETA: 0s - loss: 0.4855 - acc: 0.846 - ETA: 0s - loss: 0.4813 - acc: 0.847 - ETA: 0s - loss: 0.4810 - acc: 0.847 - ETA: 0s - loss: 0.4936 - acc: 0.841 - ETA: 0s - loss: 0.4969 - acc: 0.840 - ETA: 0s - loss: 0.5011 - acc: 0.840 - ETA: 0s - loss: 0.5041 - acc: 0.839 - ETA: 0s - loss: 0.5048 - acc: 0.838 - ETA: 0s - loss: 0.5046 - acc: 0.838 - 1s 150us/step - loss: 0.5023 - acc: 0.8395 - val_loss: 1.2053 - val_acc: 0.6464\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.16821\n",
      "Epoch 21/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.5944 - acc: 0.880 - ETA: 1s - loss: 0.5582 - acc: 0.832 - ETA: 1s - loss: 0.5475 - acc: 0.836 - ETA: 1s - loss: 0.5544 - acc: 0.837 - ETA: 0s - loss: 0.5285 - acc: 0.839 - ETA: 0s - loss: 0.5118 - acc: 0.842 - ETA: 0s - loss: 0.5078 - acc: 0.845 - ETA: 0s - loss: 0.5048 - acc: 0.841 - ETA: 0s - loss: 0.5034 - acc: 0.841 - ETA: 0s - loss: 0.5094 - acc: 0.840 - ETA: 0s - loss: 0.5097 - acc: 0.839 - ETA: 0s - loss: 0.5087 - acc: 0.839 - ETA: 0s - loss: 0.5022 - acc: 0.842 - ETA: 0s - loss: 0.5057 - acc: 0.841 - ETA: 0s - loss: 0.4979 - acc: 0.843 - ETA: 0s - loss: 0.5031 - acc: 0.841 - ETA: 0s - loss: 0.5024 - acc: 0.841 - ETA: 0s - loss: 0.5057 - acc: 0.842 - ETA: 0s - loss: 0.5020 - acc: 0.842 - ETA: 0s - loss: 0.5023 - acc: 0.841 - ETA: 0s - loss: 0.5060 - acc: 0.841 - ETA: 0s - loss: 0.5059 - acc: 0.841 - 1s 150us/step - loss: 0.5086 - acc: 0.8412 - val_loss: 1.1604 - val_acc: 0.6714\n",
      "\n",
      "Epoch 00021: val_loss improved from 1.16821 to 1.16043, saving model to Saved_models/multi_mlp.hdf5\n",
      "Epoch 22/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.4119 - acc: 0.840 - ETA: 1s - loss: 0.4953 - acc: 0.820 - ETA: 1s - loss: 0.5016 - acc: 0.821 - ETA: 0s - loss: 0.4756 - acc: 0.833 - ETA: 0s - loss: 0.4975 - acc: 0.833 - ETA: 0s - loss: 0.5012 - acc: 0.831 - ETA: 0s - loss: 0.5053 - acc: 0.834 - ETA: 0s - loss: 0.5115 - acc: 0.836 - ETA: 0s - loss: 0.5126 - acc: 0.837 - ETA: 0s - loss: 0.5083 - acc: 0.837 - ETA: 0s - loss: 0.5071 - acc: 0.837 - ETA: 0s - loss: 0.4992 - acc: 0.839 - ETA: 0s - loss: 0.4955 - acc: 0.840 - ETA: 0s - loss: 0.5040 - acc: 0.839 - ETA: 0s - loss: 0.5023 - acc: 0.841 - ETA: 0s - loss: 0.4995 - acc: 0.840 - ETA: 0s - loss: 0.4973 - acc: 0.840 - ETA: 0s - loss: 0.4994 - acc: 0.839 - ETA: 0s - loss: 0.5043 - acc: 0.838 - ETA: 0s - loss: 0.5075 - acc: 0.836 - ETA: 0s - loss: 0.5056 - acc: 0.836 - ETA: 0s - loss: 0.5036 - acc: 0.837 - 1s 151us/step - loss: 0.5041 - acc: 0.8386 - val_loss: 1.1674 - val_acc: 0.6511\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.16043\n",
      "Epoch 23/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.5151 - acc: 0.840 - ETA: 1s - loss: 0.4809 - acc: 0.840 - ETA: 1s - loss: 0.4581 - acc: 0.845 - ETA: 1s - loss: 0.4530 - acc: 0.843 - ETA: 0s - loss: 0.4508 - acc: 0.840 - ETA: 0s - loss: 0.4771 - acc: 0.837 - ETA: 0s - loss: 0.4951 - acc: 0.835 - ETA: 0s - loss: 0.5015 - acc: 0.836 - ETA: 0s - loss: 0.4928 - acc: 0.838 - ETA: 0s - loss: 0.4889 - acc: 0.838 - ETA: 0s - loss: 0.4961 - acc: 0.836 - ETA: 0s - loss: 0.4972 - acc: 0.837 - ETA: 0s - loss: 0.4950 - acc: 0.839 - ETA: 0s - loss: 0.4899 - acc: 0.841 - ETA: 0s - loss: 0.4904 - acc: 0.841 - ETA: 0s - loss: 0.4959 - acc: 0.839 - ETA: 0s - loss: 0.5009 - acc: 0.838 - ETA: 0s - loss: 0.5021 - acc: 0.837 - ETA: 0s - loss: 0.4992 - acc: 0.838 - ETA: 0s - loss: 0.4994 - acc: 0.837 - ETA: 0s - loss: 0.5025 - acc: 0.837 - ETA: 0s - loss: 0.5011 - acc: 0.838 - 1s 152us/step - loss: 0.5024 - acc: 0.8386 - val_loss: 1.1857 - val_acc: 0.6607\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00023: val_loss did not improve from 1.16043\n",
      "Epoch 24/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.3144 - acc: 0.900 - ETA: 1s - loss: 0.4309 - acc: 0.860 - ETA: 1s - loss: 0.5125 - acc: 0.832 - ETA: 1s - loss: 0.4907 - acc: 0.836 - ETA: 0s - loss: 0.4924 - acc: 0.831 - ETA: 0s - loss: 0.4946 - acc: 0.833 - ETA: 0s - loss: 0.4842 - acc: 0.837 - ETA: 0s - loss: 0.4768 - acc: 0.840 - ETA: 0s - loss: 0.4761 - acc: 0.839 - ETA: 0s - loss: 0.4751 - acc: 0.840 - ETA: 0s - loss: 0.4717 - acc: 0.843 - ETA: 0s - loss: 0.4682 - acc: 0.846 - ETA: 0s - loss: 0.4757 - acc: 0.846 - ETA: 0s - loss: 0.4766 - acc: 0.845 - ETA: 0s - loss: 0.4761 - acc: 0.845 - ETA: 0s - loss: 0.4763 - acc: 0.846 - ETA: 0s - loss: 0.4733 - acc: 0.847 - ETA: 0s - loss: 0.4788 - acc: 0.845 - ETA: 0s - loss: 0.4744 - acc: 0.846 - ETA: 0s - loss: 0.4742 - acc: 0.847 - ETA: 0s - loss: 0.4709 - acc: 0.847 - ETA: 0s - loss: 0.4795 - acc: 0.846 - 1s 152us/step - loss: 0.4777 - acc: 0.8465 - val_loss: 1.2352 - val_acc: 0.6476\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.16043\n",
      "Epoch 25/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.4632 - acc: 0.820 - ETA: 1s - loss: 0.4651 - acc: 0.842 - ETA: 1s - loss: 0.4743 - acc: 0.848 - ETA: 1s - loss: 0.4472 - acc: 0.853 - ETA: 0s - loss: 0.4443 - acc: 0.855 - ETA: 0s - loss: 0.4695 - acc: 0.849 - ETA: 0s - loss: 0.4671 - acc: 0.850 - ETA: 0s - loss: 0.4625 - acc: 0.851 - ETA: 0s - loss: 0.4756 - acc: 0.846 - ETA: 0s - loss: 0.4719 - acc: 0.847 - ETA: 0s - loss: 0.4747 - acc: 0.845 - ETA: 0s - loss: 0.4811 - acc: 0.843 - ETA: 0s - loss: 0.4808 - acc: 0.843 - ETA: 0s - loss: 0.4868 - acc: 0.841 - ETA: 0s - loss: 0.4900 - acc: 0.840 - ETA: 0s - loss: 0.4936 - acc: 0.839 - ETA: 0s - loss: 0.4893 - acc: 0.842 - ETA: 0s - loss: 0.4936 - acc: 0.841 - ETA: 0s - loss: 0.4950 - acc: 0.841 - ETA: 0s - loss: 0.4954 - acc: 0.840 - ETA: 0s - loss: 0.4940 - acc: 0.841 - ETA: 0s - loss: 0.4924 - acc: 0.842 - 1s 150us/step - loss: 0.4927 - acc: 0.8423 - val_loss: 1.2183 - val_acc: 0.6368\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.16043\n",
      "Epoch 26/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.4785 - acc: 0.900 - ETA: 1s - loss: 0.4160 - acc: 0.866 - ETA: 0s - loss: 0.5019 - acc: 0.852 - ETA: 0s - loss: 0.4956 - acc: 0.850 - ETA: 0s - loss: 0.5018 - acc: 0.849 - ETA: 0s - loss: 0.5117 - acc: 0.841 - ETA: 0s - loss: 0.4900 - acc: 0.844 - ETA: 0s - loss: 0.4970 - acc: 0.842 - ETA: 0s - loss: 0.4974 - acc: 0.842 - ETA: 0s - loss: 0.4920 - acc: 0.844 - ETA: 0s - loss: 0.5050 - acc: 0.844 - ETA: 0s - loss: 0.5050 - acc: 0.844 - ETA: 0s - loss: 0.4997 - acc: 0.846 - ETA: 0s - loss: 0.4969 - acc: 0.845 - ETA: 0s - loss: 0.4969 - acc: 0.844 - ETA: 0s - loss: 0.5019 - acc: 0.843 - ETA: 0s - loss: 0.4996 - acc: 0.843 - ETA: 0s - loss: 0.4945 - acc: 0.843 - ETA: 0s - loss: 0.5021 - acc: 0.842 - ETA: 0s - loss: 0.4975 - acc: 0.843 - ETA: 0s - loss: 0.5057 - acc: 0.840 - ETA: 0s - loss: 0.5017 - acc: 0.842 - 1s 148us/step - loss: 0.5000 - acc: 0.8427 - val_loss: 1.2180 - val_acc: 0.6416\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.16043\n",
      "Epoch 27/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.6181 - acc: 0.800 - ETA: 1s - loss: 0.4535 - acc: 0.864 - ETA: 0s - loss: 0.4441 - acc: 0.870 - ETA: 0s - loss: 0.4442 - acc: 0.867 - ETA: 0s - loss: 0.4451 - acc: 0.863 - ETA: 0s - loss: 0.4567 - acc: 0.852 - ETA: 0s - loss: 0.4801 - acc: 0.843 - ETA: 0s - loss: 0.4859 - acc: 0.842 - ETA: 0s - loss: 0.4825 - acc: 0.845 - ETA: 0s - loss: 0.4886 - acc: 0.843 - ETA: 0s - loss: 0.4861 - acc: 0.844 - ETA: 0s - loss: 0.4882 - acc: 0.842 - ETA: 0s - loss: 0.4871 - acc: 0.842 - ETA: 0s - loss: 0.4867 - acc: 0.842 - ETA: 0s - loss: 0.4868 - acc: 0.842 - ETA: 0s - loss: 0.4814 - acc: 0.844 - ETA: 0s - loss: 0.4770 - acc: 0.846 - ETA: 0s - loss: 0.4797 - acc: 0.845 - ETA: 0s - loss: 0.4826 - acc: 0.844 - ETA: 0s - loss: 0.4846 - acc: 0.845 - ETA: 0s - loss: 0.4889 - acc: 0.844 - ETA: 0s - loss: 0.4887 - acc: 0.844 - 1s 147us/step - loss: 0.4897 - acc: 0.8448 - val_loss: 1.3369 - val_acc: 0.6117\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.16043\n",
      "Epoch 28/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.5466 - acc: 0.840 - ETA: 1s - loss: 0.5016 - acc: 0.846 - ETA: 1s - loss: 0.4972 - acc: 0.846 - ETA: 0s - loss: 0.5102 - acc: 0.839 - ETA: 0s - loss: 0.5060 - acc: 0.841 - ETA: 0s - loss: 0.4979 - acc: 0.842 - ETA: 0s - loss: 0.4916 - acc: 0.843 - ETA: 0s - loss: 0.4867 - acc: 0.846 - ETA: 0s - loss: 0.4855 - acc: 0.844 - ETA: 0s - loss: 0.4890 - acc: 0.843 - ETA: 0s - loss: 0.4853 - acc: 0.843 - ETA: 0s - loss: 0.4833 - acc: 0.845 - ETA: 0s - loss: 0.4849 - acc: 0.842 - ETA: 0s - loss: 0.4891 - acc: 0.841 - ETA: 0s - loss: 0.4925 - acc: 0.839 - ETA: 0s - loss: 0.4952 - acc: 0.838 - ETA: 0s - loss: 0.4968 - acc: 0.839 - ETA: 0s - loss: 0.4949 - acc: 0.839 - ETA: 0s - loss: 0.4934 - acc: 0.840 - ETA: 0s - loss: 0.4925 - acc: 0.841 - ETA: 0s - loss: 0.4975 - acc: 0.842 - 1s 146us/step - loss: 0.4949 - acc: 0.8427 - val_loss: 1.2601 - val_acc: 0.6332\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.16043\n",
      "Epoch 29/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.4563 - acc: 0.880 - ETA: 1s - loss: 0.4357 - acc: 0.852 - ETA: 1s - loss: 0.4523 - acc: 0.855 - ETA: 0s - loss: 0.4360 - acc: 0.855 - ETA: 0s - loss: 0.4477 - acc: 0.854 - ETA: 0s - loss: 0.4517 - acc: 0.851 - ETA: 0s - loss: 0.4419 - acc: 0.853 - ETA: 0s - loss: 0.4468 - acc: 0.851 - ETA: 0s - loss: 0.4584 - acc: 0.849 - ETA: 0s - loss: 0.4538 - acc: 0.851 - ETA: 0s - loss: 0.4624 - acc: 0.847 - ETA: 0s - loss: 0.4689 - acc: 0.847 - ETA: 0s - loss: 0.4748 - acc: 0.844 - ETA: 0s - loss: 0.4790 - acc: 0.843 - ETA: 0s - loss: 0.4738 - acc: 0.845 - ETA: 0s - loss: 0.4754 - acc: 0.846 - ETA: 0s - loss: 0.4707 - acc: 0.846 - ETA: 0s - loss: 0.4690 - acc: 0.847 - ETA: 0s - loss: 0.4736 - acc: 0.845 - ETA: 0s - loss: 0.4743 - acc: 0.845 - ETA: 0s - loss: 0.4773 - acc: 0.844 - ETA: 0s - loss: 0.4784 - acc: 0.844 - ETA: 0s - loss: 0.4795 - acc: 0.844 - 1s 153us/step - loss: 0.4774 - acc: 0.8457 - val_loss: 1.2275 - val_acc: 0.6511\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.16043\n",
      "Epoch 30/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.4071 - acc: 0.900 - ETA: 1s - loss: 0.4149 - acc: 0.885 - ETA: 1s - loss: 0.4482 - acc: 0.864 - ETA: 0s - loss: 0.4624 - acc: 0.851 - ETA: 0s - loss: 0.4801 - acc: 0.839 - ETA: 0s - loss: 0.4778 - acc: 0.840 - ETA: 0s - loss: 0.4740 - acc: 0.843 - ETA: 0s - loss: 0.4623 - acc: 0.848 - ETA: 0s - loss: 0.4698 - acc: 0.850 - ETA: 0s - loss: 0.4739 - acc: 0.845 - ETA: 0s - loss: 0.4773 - acc: 0.845 - ETA: 0s - loss: 0.4857 - acc: 0.842 - ETA: 0s - loss: 0.4880 - acc: 0.842 - ETA: 0s - loss: 0.4925 - acc: 0.841 - ETA: 0s - loss: 0.4873 - acc: 0.841 - ETA: 0s - loss: 0.4839 - acc: 0.842 - ETA: 0s - loss: 0.4853 - acc: 0.842 - ETA: 0s - loss: 0.4811 - acc: 0.844 - ETA: 0s - loss: 0.4803 - acc: 0.845 - ETA: 0s - loss: 0.4785 - acc: 0.846 - ETA: 0s - loss: 0.4735 - acc: 0.848 - ETA: 0s - loss: 0.4706 - acc: 0.848 - ETA: 0s - loss: 0.4683 - acc: 0.849 - 1s 157us/step - loss: 0.4691 - acc: 0.8498 - val_loss: 1.2412 - val_acc: 0.6380\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.16043\n",
      "Epoch 31/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.5888 - acc: 0.840 - ETA: 1s - loss: 0.5171 - acc: 0.835 - ETA: 1s - loss: 0.4720 - acc: 0.842 - ETA: 1s - loss: 0.4931 - acc: 0.841 - ETA: 0s - loss: 0.4868 - acc: 0.843 - ETA: 0s - loss: 0.4944 - acc: 0.840 - ETA: 0s - loss: 0.4976 - acc: 0.840 - ETA: 0s - loss: 0.4935 - acc: 0.839 - ETA: 0s - loss: 0.4882 - acc: 0.842 - ETA: 0s - loss: 0.4827 - acc: 0.844 - ETA: 0s - loss: 0.4756 - acc: 0.845 - ETA: 0s - loss: 0.4689 - acc: 0.848 - ETA: 0s - loss: 0.4626 - acc: 0.849 - ETA: 0s - loss: 0.4624 - acc: 0.850 - ETA: 0s - loss: 0.4595 - acc: 0.852 - ETA: 0s - loss: 0.4601 - acc: 0.851 - ETA: 0s - loss: 0.4585 - acc: 0.851 - ETA: 0s - loss: 0.4590 - acc: 0.851 - ETA: 0s - loss: 0.4628 - acc: 0.851 - ETA: 0s - loss: 0.4625 - acc: 0.851 - ETA: 0s - loss: 0.4660 - acc: 0.850 - 1s 140us/step - loss: 0.4648 - acc: 0.8508 - val_loss: 1.2165 - val_acc: 0.6523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00031: val_loss did not improve from 1.16043\n",
      "Epoch 32/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.5514 - acc: 0.720 - ETA: 0s - loss: 0.4945 - acc: 0.824 - ETA: 0s - loss: 0.4538 - acc: 0.853 - ETA: 0s - loss: 0.4670 - acc: 0.856 - ETA: 0s - loss: 0.4568 - acc: 0.858 - ETA: 0s - loss: 0.4602 - acc: 0.855 - ETA: 0s - loss: 0.4567 - acc: 0.854 - ETA: 0s - loss: 0.4578 - acc: 0.852 - ETA: 0s - loss: 0.4624 - acc: 0.851 - ETA: 0s - loss: 0.4701 - acc: 0.849 - ETA: 0s - loss: 0.4637 - acc: 0.850 - ETA: 0s - loss: 0.4683 - acc: 0.850 - ETA: 0s - loss: 0.4616 - acc: 0.851 - ETA: 0s - loss: 0.4609 - acc: 0.851 - ETA: 0s - loss: 0.4578 - acc: 0.853 - ETA: 0s - loss: 0.4658 - acc: 0.850 - ETA: 0s - loss: 0.4714 - acc: 0.848 - ETA: 0s - loss: 0.4756 - acc: 0.847 - ETA: 0s - loss: 0.4737 - acc: 0.849 - ETA: 0s - loss: 0.4733 - acc: 0.849 - ETA: 0s - loss: 0.4717 - acc: 0.849 - 1s 145us/step - loss: 0.4740 - acc: 0.8481 - val_loss: 1.2291 - val_acc: 0.6595\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.16043\n",
      "Epoch 33/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.6456 - acc: 0.740 - ETA: 1s - loss: 0.4441 - acc: 0.847 - ETA: 1s - loss: 0.4547 - acc: 0.842 - ETA: 0s - loss: 0.4389 - acc: 0.852 - ETA: 0s - loss: 0.4486 - acc: 0.851 - ETA: 0s - loss: 0.4389 - acc: 0.856 - ETA: 0s - loss: 0.4314 - acc: 0.859 - ETA: 0s - loss: 0.4509 - acc: 0.855 - ETA: 0s - loss: 0.4468 - acc: 0.857 - ETA: 0s - loss: 0.4546 - acc: 0.857 - ETA: 0s - loss: 0.4506 - acc: 0.857 - ETA: 0s - loss: 0.4592 - acc: 0.857 - ETA: 0s - loss: 0.4651 - acc: 0.856 - ETA: 0s - loss: 0.4663 - acc: 0.854 - ETA: 0s - loss: 0.4675 - acc: 0.855 - ETA: 0s - loss: 0.4748 - acc: 0.853 - ETA: 0s - loss: 0.4746 - acc: 0.853 - ETA: 0s - loss: 0.4734 - acc: 0.853 - ETA: 0s - loss: 0.4723 - acc: 0.853 - ETA: 0s - loss: 0.4737 - acc: 0.854 - ETA: 0s - loss: 0.4798 - acc: 0.852 - 1s 145us/step - loss: 0.4772 - acc: 0.8529 - val_loss: 1.2238 - val_acc: 0.6404\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.16043\n",
      "Epoch 34/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.5474 - acc: 0.860 - ETA: 1s - loss: 0.4367 - acc: 0.862 - ETA: 1s - loss: 0.4513 - acc: 0.855 - ETA: 0s - loss: 0.4909 - acc: 0.847 - ETA: 0s - loss: 0.4865 - acc: 0.844 - ETA: 0s - loss: 0.4769 - acc: 0.847 - ETA: 0s - loss: 0.4743 - acc: 0.848 - ETA: 0s - loss: 0.4659 - acc: 0.852 - ETA: 0s - loss: 0.4651 - acc: 0.853 - ETA: 0s - loss: 0.4692 - acc: 0.854 - ETA: 0s - loss: 0.4640 - acc: 0.854 - ETA: 0s - loss: 0.4571 - acc: 0.855 - ETA: 0s - loss: 0.4603 - acc: 0.855 - ETA: 0s - loss: 0.4547 - acc: 0.856 - ETA: 0s - loss: 0.4551 - acc: 0.854 - ETA: 0s - loss: 0.4540 - acc: 0.854 - ETA: 0s - loss: 0.4525 - acc: 0.855 - ETA: 0s - loss: 0.4511 - acc: 0.856 - ETA: 0s - loss: 0.4507 - acc: 0.858 - ETA: 0s - loss: 0.4523 - acc: 0.858 - ETA: 0s - loss: 0.4515 - acc: 0.857 - 1s 145us/step - loss: 0.4504 - acc: 0.8581 - val_loss: 1.3107 - val_acc: 0.6308\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.16043\n",
      "Epoch 35/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.4225 - acc: 0.840 - ETA: 1s - loss: 0.3646 - acc: 0.877 - ETA: 1s - loss: 0.3834 - acc: 0.858 - ETA: 0s - loss: 0.3819 - acc: 0.860 - ETA: 0s - loss: 0.3875 - acc: 0.869 - ETA: 0s - loss: 0.4025 - acc: 0.865 - ETA: 0s - loss: 0.4107 - acc: 0.865 - ETA: 0s - loss: 0.4137 - acc: 0.865 - ETA: 0s - loss: 0.4102 - acc: 0.867 - ETA: 0s - loss: 0.4334 - acc: 0.861 - ETA: 0s - loss: 0.4375 - acc: 0.860 - ETA: 0s - loss: 0.4408 - acc: 0.860 - ETA: 0s - loss: 0.4435 - acc: 0.858 - ETA: 0s - loss: 0.4419 - acc: 0.857 - ETA: 0s - loss: 0.4430 - acc: 0.857 - ETA: 0s - loss: 0.4455 - acc: 0.856 - ETA: 0s - loss: 0.4492 - acc: 0.854 - ETA: 0s - loss: 0.4474 - acc: 0.854 - ETA: 0s - loss: 0.4554 - acc: 0.854 - ETA: 0s - loss: 0.4595 - acc: 0.853 - ETA: 0s - loss: 0.4625 - acc: 0.853 - 1s 142us/step - loss: 0.4634 - acc: 0.8533 - val_loss: 1.2526 - val_acc: 0.6499\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1.16043\n",
      "Epoch 36/50\n",
      "7895/7895 [==============================] - ETA: 0s - loss: 0.3165 - acc: 0.920 - ETA: 0s - loss: 0.4312 - acc: 0.860 - ETA: 0s - loss: 0.4478 - acc: 0.840 - ETA: 0s - loss: 0.4481 - acc: 0.840 - ETA: 0s - loss: 0.4763 - acc: 0.840 - ETA: 0s - loss: 0.4640 - acc: 0.843 - ETA: 0s - loss: 0.4807 - acc: 0.841 - ETA: 0s - loss: 0.4701 - acc: 0.846 - ETA: 0s - loss: 0.4599 - acc: 0.850 - ETA: 0s - loss: 0.4518 - acc: 0.850 - ETA: 0s - loss: 0.4467 - acc: 0.853 - ETA: 0s - loss: 0.4443 - acc: 0.855 - ETA: 0s - loss: 0.4393 - acc: 0.857 - ETA: 0s - loss: 0.4397 - acc: 0.858 - ETA: 0s - loss: 0.4373 - acc: 0.858 - ETA: 0s - loss: 0.4381 - acc: 0.860 - ETA: 0s - loss: 0.4403 - acc: 0.857 - ETA: 0s - loss: 0.4443 - acc: 0.857 - ETA: 0s - loss: 0.4463 - acc: 0.857 - ETA: 0s - loss: 0.4467 - acc: 0.857 - ETA: 0s - loss: 0.4457 - acc: 0.857 - 1s 142us/step - loss: 0.4426 - acc: 0.8583 - val_loss: 1.3804 - val_acc: 0.6081\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1.16043\n",
      "Epoch 37/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.3972 - acc: 0.860 - ETA: 0s - loss: 0.4258 - acc: 0.862 - ETA: 0s - loss: 0.4105 - acc: 0.866 - ETA: 0s - loss: 0.4380 - acc: 0.863 - ETA: 0s - loss: 0.4331 - acc: 0.868 - ETA: 0s - loss: 0.4328 - acc: 0.864 - ETA: 0s - loss: 0.4341 - acc: 0.863 - ETA: 0s - loss: 0.4339 - acc: 0.866 - ETA: 0s - loss: 0.4287 - acc: 0.865 - ETA: 0s - loss: 0.4359 - acc: 0.866 - ETA: 0s - loss: 0.4350 - acc: 0.866 - ETA: 0s - loss: 0.4338 - acc: 0.868 - ETA: 0s - loss: 0.4423 - acc: 0.864 - ETA: 0s - loss: 0.4480 - acc: 0.862 - ETA: 0s - loss: 0.4536 - acc: 0.861 - ETA: 0s - loss: 0.4611 - acc: 0.859 - ETA: 0s - loss: 0.4642 - acc: 0.857 - ETA: 0s - loss: 0.4603 - acc: 0.858 - ETA: 0s - loss: 0.4613 - acc: 0.858 - ETA: 0s - loss: 0.4592 - acc: 0.859 - ETA: 0s - loss: 0.4547 - acc: 0.860 - 1s 142us/step - loss: 0.4554 - acc: 0.8609 - val_loss: 1.2757 - val_acc: 0.6260\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1.16043\n",
      "Epoch 38/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.6176 - acc: 0.860 - ETA: 1s - loss: 0.4696 - acc: 0.855 - ETA: 0s - loss: 0.4600 - acc: 0.851 - ETA: 0s - loss: 0.4732 - acc: 0.856 - ETA: 0s - loss: 0.4598 - acc: 0.861 - ETA: 0s - loss: 0.4435 - acc: 0.866 - ETA: 0s - loss: 0.4462 - acc: 0.864 - ETA: 0s - loss: 0.4320 - acc: 0.868 - ETA: 0s - loss: 0.4301 - acc: 0.867 - ETA: 0s - loss: 0.4207 - acc: 0.869 - ETA: 0s - loss: 0.4214 - acc: 0.869 - ETA: 0s - loss: 0.4250 - acc: 0.869 - ETA: 0s - loss: 0.4254 - acc: 0.868 - ETA: 0s - loss: 0.4269 - acc: 0.867 - ETA: 0s - loss: 0.4315 - acc: 0.866 - ETA: 0s - loss: 0.4264 - acc: 0.867 - ETA: 0s - loss: 0.4301 - acc: 0.865 - ETA: 0s - loss: 0.4321 - acc: 0.865 - ETA: 0s - loss: 0.4274 - acc: 0.867 - ETA: 0s - loss: 0.4279 - acc: 0.868 - ETA: 0s - loss: 0.4292 - acc: 0.868 - 1s 143us/step - loss: 0.4290 - acc: 0.8678 - val_loss: 1.3400 - val_acc: 0.6284\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.16043\n",
      "Epoch 39/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.4136 - acc: 0.880 - ETA: 0s - loss: 0.4475 - acc: 0.862 - ETA: 0s - loss: 0.4389 - acc: 0.868 - ETA: 0s - loss: 0.4169 - acc: 0.874 - ETA: 0s - loss: 0.4272 - acc: 0.872 - ETA: 0s - loss: 0.4298 - acc: 0.870 - ETA: 0s - loss: 0.4315 - acc: 0.867 - ETA: 0s - loss: 0.4323 - acc: 0.866 - ETA: 0s - loss: 0.4443 - acc: 0.863 - ETA: 0s - loss: 0.4436 - acc: 0.862 - ETA: 0s - loss: 0.4438 - acc: 0.863 - ETA: 0s - loss: 0.4415 - acc: 0.863 - ETA: 0s - loss: 0.4393 - acc: 0.865 - ETA: 0s - loss: 0.4382 - acc: 0.865 - ETA: 0s - loss: 0.4394 - acc: 0.865 - ETA: 0s - loss: 0.4389 - acc: 0.866 - ETA: 0s - loss: 0.4366 - acc: 0.867 - ETA: 0s - loss: 0.4377 - acc: 0.867 - ETA: 0s - loss: 0.4391 - acc: 0.866 - ETA: 0s - loss: 0.4358 - acc: 0.866 - ETA: 0s - loss: 0.4379 - acc: 0.867 - 1s 144us/step - loss: 0.4401 - acc: 0.8665 - val_loss: 1.3189 - val_acc: 0.6320\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1.16043\n",
      "Epoch 40/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7895/7895 [==============================] - ETA: 1s - loss: 0.4182 - acc: 0.860 - ETA: 1s - loss: 0.4243 - acc: 0.846 - ETA: 0s - loss: 0.3965 - acc: 0.863 - ETA: 0s - loss: 0.3997 - acc: 0.866 - ETA: 0s - loss: 0.4053 - acc: 0.865 - ETA: 0s - loss: 0.4202 - acc: 0.859 - ETA: 0s - loss: 0.4269 - acc: 0.864 - ETA: 0s - loss: 0.4212 - acc: 0.865 - ETA: 0s - loss: 0.4217 - acc: 0.863 - ETA: 0s - loss: 0.4231 - acc: 0.862 - ETA: 0s - loss: 0.4253 - acc: 0.863 - ETA: 0s - loss: 0.4295 - acc: 0.862 - ETA: 0s - loss: 0.4388 - acc: 0.860 - ETA: 0s - loss: 0.4335 - acc: 0.861 - ETA: 0s - loss: 0.4334 - acc: 0.862 - ETA: 0s - loss: 0.4343 - acc: 0.863 - ETA: 0s - loss: 0.4338 - acc: 0.863 - ETA: 0s - loss: 0.4335 - acc: 0.863 - ETA: 0s - loss: 0.4351 - acc: 0.863 - ETA: 0s - loss: 0.4314 - acc: 0.864 - ETA: 0s - loss: 0.4300 - acc: 0.864 - 1s 145us/step - loss: 0.4329 - acc: 0.8632 - val_loss: 1.2049 - val_acc: 0.6691\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.16043\n",
      "Epoch 41/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.3472 - acc: 0.880 - ETA: 1s - loss: 0.4260 - acc: 0.852 - ETA: 1s - loss: 0.4350 - acc: 0.846 - ETA: 0s - loss: 0.4112 - acc: 0.853 - ETA: 0s - loss: 0.4158 - acc: 0.856 - ETA: 0s - loss: 0.4250 - acc: 0.853 - ETA: 0s - loss: 0.4228 - acc: 0.854 - ETA: 0s - loss: 0.4248 - acc: 0.853 - ETA: 0s - loss: 0.4430 - acc: 0.851 - ETA: 0s - loss: 0.4427 - acc: 0.854 - ETA: 0s - loss: 0.4448 - acc: 0.854 - ETA: 0s - loss: 0.4472 - acc: 0.854 - ETA: 0s - loss: 0.4562 - acc: 0.854 - ETA: 0s - loss: 0.4565 - acc: 0.853 - ETA: 0s - loss: 0.4562 - acc: 0.854 - ETA: 0s - loss: 0.4525 - acc: 0.855 - ETA: 0s - loss: 0.4551 - acc: 0.855 - ETA: 0s - loss: 0.4513 - acc: 0.856 - ETA: 0s - loss: 0.4509 - acc: 0.856 - ETA: 0s - loss: 0.4492 - acc: 0.857 - ETA: 0s - loss: 0.4460 - acc: 0.858 - 1s 145us/step - loss: 0.4396 - acc: 0.8598 - val_loss: 1.3149 - val_acc: 0.6225\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1.16043\n",
      "Epoch 42/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.3161 - acc: 0.820 - ETA: 1s - loss: 0.4278 - acc: 0.860 - ETA: 1s - loss: 0.3851 - acc: 0.872 - ETA: 0s - loss: 0.4150 - acc: 0.871 - ETA: 0s - loss: 0.4240 - acc: 0.866 - ETA: 0s - loss: 0.4190 - acc: 0.871 - ETA: 0s - loss: 0.4193 - acc: 0.870 - ETA: 0s - loss: 0.4093 - acc: 0.871 - ETA: 0s - loss: 0.4056 - acc: 0.870 - ETA: 0s - loss: 0.4064 - acc: 0.869 - ETA: 0s - loss: 0.4192 - acc: 0.867 - ETA: 0s - loss: 0.4258 - acc: 0.863 - ETA: 0s - loss: 0.4288 - acc: 0.865 - ETA: 0s - loss: 0.4429 - acc: 0.860 - ETA: 0s - loss: 0.4448 - acc: 0.858 - ETA: 0s - loss: 0.4436 - acc: 0.857 - ETA: 0s - loss: 0.4378 - acc: 0.858 - ETA: 0s - loss: 0.4328 - acc: 0.859 - ETA: 0s - loss: 0.4315 - acc: 0.860 - ETA: 0s - loss: 0.4368 - acc: 0.859 - ETA: 0s - loss: 0.4365 - acc: 0.859 - 1s 144us/step - loss: 0.4362 - acc: 0.8603 - val_loss: 1.2776 - val_acc: 0.6380\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.16043\n",
      "Epoch 43/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.1973 - acc: 0.920 - ETA: 1s - loss: 0.4897 - acc: 0.840 - ETA: 1s - loss: 0.4399 - acc: 0.856 - ETA: 0s - loss: 0.4445 - acc: 0.862 - ETA: 0s - loss: 0.4301 - acc: 0.864 - ETA: 0s - loss: 0.4027 - acc: 0.872 - ETA: 0s - loss: 0.4157 - acc: 0.872 - ETA: 0s - loss: 0.4257 - acc: 0.870 - ETA: 0s - loss: 0.4321 - acc: 0.866 - ETA: 0s - loss: 0.4325 - acc: 0.865 - ETA: 0s - loss: 0.4412 - acc: 0.863 - ETA: 0s - loss: 0.4395 - acc: 0.865 - ETA: 0s - loss: 0.4411 - acc: 0.864 - ETA: 0s - loss: 0.4389 - acc: 0.864 - ETA: 0s - loss: 0.4344 - acc: 0.864 - ETA: 0s - loss: 0.4347 - acc: 0.864 - ETA: 0s - loss: 0.4376 - acc: 0.864 - ETA: 0s - loss: 0.4433 - acc: 0.862 - ETA: 0s - loss: 0.4436 - acc: 0.862 - ETA: 0s - loss: 0.4442 - acc: 0.862 - ETA: 0s - loss: 0.4408 - acc: 0.863 - 1s 146us/step - loss: 0.4431 - acc: 0.8632 - val_loss: 1.3116 - val_acc: 0.6344\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1.16043\n",
      "Epoch 44/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.5727 - acc: 0.800 - ETA: 1s - loss: 0.5175 - acc: 0.848 - ETA: 1s - loss: 0.4795 - acc: 0.860 - ETA: 0s - loss: 0.4724 - acc: 0.855 - ETA: 0s - loss: 0.4831 - acc: 0.856 - ETA: 0s - loss: 0.4786 - acc: 0.857 - ETA: 0s - loss: 0.4760 - acc: 0.858 - ETA: 0s - loss: 0.4650 - acc: 0.858 - ETA: 0s - loss: 0.4559 - acc: 0.861 - ETA: 0s - loss: 0.4561 - acc: 0.859 - ETA: 0s - loss: 0.4555 - acc: 0.859 - ETA: 0s - loss: 0.4611 - acc: 0.857 - ETA: 0s - loss: 0.4585 - acc: 0.856 - ETA: 0s - loss: 0.4657 - acc: 0.855 - ETA: 0s - loss: 0.4611 - acc: 0.857 - ETA: 0s - loss: 0.4589 - acc: 0.857 - ETA: 0s - loss: 0.4605 - acc: 0.857 - ETA: 0s - loss: 0.4584 - acc: 0.857 - ETA: 0s - loss: 0.4660 - acc: 0.856 - ETA: 0s - loss: 0.4620 - acc: 0.857 - ETA: 0s - loss: 0.4614 - acc: 0.858 - ETA: 0s - loss: 0.4606 - acc: 0.858 - 1s 148us/step - loss: 0.4595 - acc: 0.8585 - val_loss: 1.3623 - val_acc: 0.6165\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1.16043\n",
      "Epoch 45/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.3714 - acc: 0.900 - ETA: 1s - loss: 0.3991 - acc: 0.877 - ETA: 1s - loss: 0.4606 - acc: 0.853 - ETA: 0s - loss: 0.4592 - acc: 0.851 - ETA: 0s - loss: 0.4688 - acc: 0.852 - ETA: 0s - loss: 0.4410 - acc: 0.859 - ETA: 0s - loss: 0.4329 - acc: 0.862 - ETA: 0s - loss: 0.4278 - acc: 0.865 - ETA: 0s - loss: 0.4142 - acc: 0.870 - ETA: 0s - loss: 0.4217 - acc: 0.868 - ETA: 0s - loss: 0.4181 - acc: 0.872 - ETA: 0s - loss: 0.4269 - acc: 0.871 - ETA: 0s - loss: 0.4264 - acc: 0.870 - ETA: 0s - loss: 0.4304 - acc: 0.868 - ETA: 0s - loss: 0.4296 - acc: 0.867 - ETA: 0s - loss: 0.4270 - acc: 0.866 - ETA: 0s - loss: 0.4331 - acc: 0.865 - ETA: 0s - loss: 0.4391 - acc: 0.863 - ETA: 0s - loss: 0.4406 - acc: 0.862 - ETA: 0s - loss: 0.4431 - acc: 0.862 - ETA: 0s - loss: 0.4419 - acc: 0.862 - 1s 146us/step - loss: 0.4394 - acc: 0.8637 - val_loss: 1.3232 - val_acc: 0.6177\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1.16043\n",
      "Epoch 46/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.6831 - acc: 0.820 - ETA: 1s - loss: 0.4662 - acc: 0.847 - ETA: 1s - loss: 0.4032 - acc: 0.871 - ETA: 1s - loss: 0.4299 - acc: 0.866 - ETA: 1s - loss: 0.4342 - acc: 0.866 - ETA: 0s - loss: 0.4255 - acc: 0.866 - ETA: 0s - loss: 0.4246 - acc: 0.868 - ETA: 0s - loss: 0.4231 - acc: 0.869 - ETA: 0s - loss: 0.4362 - acc: 0.864 - ETA: 0s - loss: 0.4312 - acc: 0.866 - ETA: 0s - loss: 0.4244 - acc: 0.868 - ETA: 0s - loss: 0.4249 - acc: 0.869 - ETA: 0s - loss: 0.4229 - acc: 0.871 - ETA: 0s - loss: 0.4241 - acc: 0.869 - ETA: 0s - loss: 0.4233 - acc: 0.870 - ETA: 0s - loss: 0.4245 - acc: 0.869 - ETA: 0s - loss: 0.4252 - acc: 0.869 - ETA: 0s - loss: 0.4241 - acc: 0.869 - ETA: 0s - loss: 0.4213 - acc: 0.869 - ETA: 0s - loss: 0.4203 - acc: 0.867 - ETA: 0s - loss: 0.4231 - acc: 0.866 - 1s 148us/step - loss: 0.4229 - acc: 0.8670 - val_loss: 1.3114 - val_acc: 0.6308\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1.16043\n",
      "Epoch 47/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.2894 - acc: 0.900 - ETA: 1s - loss: 0.4098 - acc: 0.867 - ETA: 1s - loss: 0.4130 - acc: 0.862 - ETA: 1s - loss: 0.4107 - acc: 0.863 - ETA: 0s - loss: 0.3875 - acc: 0.870 - ETA: 0s - loss: 0.3945 - acc: 0.870 - ETA: 0s - loss: 0.4072 - acc: 0.867 - ETA: 0s - loss: 0.4150 - acc: 0.864 - ETA: 0s - loss: 0.4198 - acc: 0.862 - ETA: 0s - loss: 0.4327 - acc: 0.861 - ETA: 0s - loss: 0.4333 - acc: 0.861 - ETA: 0s - loss: 0.4286 - acc: 0.861 - ETA: 0s - loss: 0.4285 - acc: 0.861 - ETA: 0s - loss: 0.4367 - acc: 0.857 - ETA: 0s - loss: 0.4340 - acc: 0.857 - ETA: 0s - loss: 0.4378 - acc: 0.856 - ETA: 0s - loss: 0.4421 - acc: 0.854 - ETA: 0s - loss: 0.4400 - acc: 0.855 - ETA: 0s - loss: 0.4453 - acc: 0.854 - ETA: 0s - loss: 0.4448 - acc: 0.855 - ETA: 0s - loss: 0.4417 - acc: 0.856 - 1s 146us/step - loss: 0.4393 - acc: 0.8570 - val_loss: 1.2766 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1.16043\n",
      "Epoch 48/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7895/7895 [==============================] - ETA: 1s - loss: 0.3977 - acc: 0.860 - ETA: 1s - loss: 0.4779 - acc: 0.860 - ETA: 1s - loss: 0.4556 - acc: 0.865 - ETA: 0s - loss: 0.4475 - acc: 0.863 - ETA: 0s - loss: 0.4492 - acc: 0.861 - ETA: 0s - loss: 0.4464 - acc: 0.860 - ETA: 0s - loss: 0.4418 - acc: 0.858 - ETA: 0s - loss: 0.4421 - acc: 0.856 - ETA: 0s - loss: 0.4511 - acc: 0.855 - ETA: 0s - loss: 0.4406 - acc: 0.860 - ETA: 0s - loss: 0.4372 - acc: 0.858 - ETA: 0s - loss: 0.4302 - acc: 0.860 - ETA: 0s - loss: 0.4339 - acc: 0.859 - ETA: 0s - loss: 0.4314 - acc: 0.859 - ETA: 0s - loss: 0.4315 - acc: 0.862 - ETA: 0s - loss: 0.4300 - acc: 0.862 - ETA: 0s - loss: 0.4333 - acc: 0.861 - ETA: 0s - loss: 0.4347 - acc: 0.861 - ETA: 0s - loss: 0.4331 - acc: 0.862 - ETA: 0s - loss: 0.4307 - acc: 0.862 - ETA: 0s - loss: 0.4330 - acc: 0.862 - 1s 144us/step - loss: 0.4289 - acc: 0.8638 - val_loss: 1.4682 - val_acc: 0.6320\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1.16043\n",
      "Epoch 49/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.4624 - acc: 0.880 - ETA: 1s - loss: 0.3442 - acc: 0.895 - ETA: 1s - loss: 0.3874 - acc: 0.886 - ETA: 0s - loss: 0.4200 - acc: 0.876 - ETA: 0s - loss: 0.4268 - acc: 0.871 - ETA: 0s - loss: 0.4205 - acc: 0.873 - ETA: 0s - loss: 0.4340 - acc: 0.866 - ETA: 0s - loss: 0.4407 - acc: 0.867 - ETA: 0s - loss: 0.4391 - acc: 0.864 - ETA: 0s - loss: 0.4442 - acc: 0.865 - ETA: 0s - loss: 0.4472 - acc: 0.864 - ETA: 0s - loss: 0.4492 - acc: 0.862 - ETA: 0s - loss: 0.4497 - acc: 0.861 - ETA: 0s - loss: 0.4452 - acc: 0.863 - ETA: 0s - loss: 0.4498 - acc: 0.862 - ETA: 0s - loss: 0.4493 - acc: 0.863 - ETA: 0s - loss: 0.4504 - acc: 0.864 - ETA: 0s - loss: 0.4492 - acc: 0.863 - ETA: 0s - loss: 0.4454 - acc: 0.865 - ETA: 0s - loss: 0.4473 - acc: 0.864 - ETA: 0s - loss: 0.4472 - acc: 0.864 - 1s 144us/step - loss: 0.4503 - acc: 0.8640 - val_loss: 1.2998 - val_acc: 0.6308\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1.16043\n",
      "Epoch 50/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.3670 - acc: 0.920 - ETA: 1s - loss: 0.3916 - acc: 0.871 - ETA: 0s - loss: 0.3828 - acc: 0.869 - ETA: 0s - loss: 0.4324 - acc: 0.856 - ETA: 0s - loss: 0.4343 - acc: 0.854 - ETA: 0s - loss: 0.4247 - acc: 0.857 - ETA: 0s - loss: 0.4376 - acc: 0.859 - ETA: 0s - loss: 0.4356 - acc: 0.860 - ETA: 0s - loss: 0.4344 - acc: 0.861 - ETA: 0s - loss: 0.4344 - acc: 0.861 - ETA: 0s - loss: 0.4322 - acc: 0.861 - ETA: 0s - loss: 0.4300 - acc: 0.861 - ETA: 0s - loss: 0.4259 - acc: 0.863 - ETA: 0s - loss: 0.4242 - acc: 0.864 - ETA: 0s - loss: 0.4249 - acc: 0.864 - ETA: 0s - loss: 0.4252 - acc: 0.864 - ETA: 0s - loss: 0.4223 - acc: 0.865 - ETA: 0s - loss: 0.4279 - acc: 0.865 - ETA: 0s - loss: 0.4267 - acc: 0.866 - ETA: 0s - loss: 0.4237 - acc: 0.867 - ETA: 0s - loss: 0.4239 - acc: 0.866 - 1s 143us/step - loss: 0.4260 - acc: 0.8661 - val_loss: 1.3290 - val_acc: 0.6487\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1.16043\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22521a33f28>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint \n",
    "#fitting\n",
    "model.fit(x_train,y_train,epochs=50,validation_data=(x_test,y_test),batch_size=50,callbacks=[ModelCheckpoint(filepath='Saved_models/multi_mlp.hdf5', verbose=1, save_best_only=True)], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 256)               51456     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 185,610\n",
      "Trainable params: 185,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "7895/7895 [==============================] - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 0s 48us/step\n",
      "837/837 [==============================] - ETA:  - 0s 51us/step\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "\n",
    "# Calculate training accuracy \n",
    "score_train = model.evaluate(x_train, y_train, verbose=1)\n",
    "score_test = model.evaluate(x_test, y_test, verbose=1)\n",
    "accuracy_train = 100*score_train[1]\n",
    "accuracy_test = 100*score_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 94.9335%\n",
      "Test accuracy: 64.8746%\n"
     ]
    }
   ],
   "source": [
    "print(\"Training accuracy: %.4f%%\" % accuracy_train)\n",
    "print(\"Test accuracy: %.4f%%\" % accuracy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(file_path):\n",
    "    y,sr=librosa.load(file_path)\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y, sr, n_mfcc=40).T,axis=0)\n",
    "    melspectrogram = np.mean(librosa.feature.melspectrogram(y=y, sr=sr, n_mels=40,fmax=8000).T,axis=0)\n",
    "    chroma_stft=np.mean(librosa.feature.chroma_stft(y=y, sr=sr,n_chroma=40).T,axis=0)\n",
    "    chroma_cq = np.mean(librosa.feature.chroma_cqt(y=y, sr=sr,n_chroma=40).T,axis=0)\n",
    "    chroma_cens = np.mean(librosa.feature.chroma_cens(y=y, sr=sr,n_chroma=40).T,axis=0)\n",
    "    features=np.reshape(np.vstack((mfccs,melspectrogram,chroma_stft,chroma_cq,chroma_cens)),(1,200))\n",
    "    #print(features.shape)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_lable=[\"air_conditioner\",\"car_horn\",\"children_playing\",\"dog_bark\",\"drilling\",\"engine_idling\",\"gun_shot\",\"jackhammer\",\"siren\",\"street_music\"]\n",
    "def print_prediction(file_path):\n",
    "    features = extract_features(file_path)\n",
    "    predicted_vector = model.predict_classes(features)\n",
    "    predicted_class = class_lable[predicted_vector[0]] \n",
    "    print(\"The predicted class is:\", predicted_class, '\\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 200)\n",
      "The predicted class is: dog_bark \n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_path='UrbanSound8K/audio/fold5/100032-3-0-0.wav'\n",
    "print_prediction(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: street_music \n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_path='UrbanSound8K/audio/fold7/101848-9-0-0.wav'\n",
    "print_prediction(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: gun_shot \n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_path='UrbanSound8K/audio/fold10/200460-6-1-0.wav'\n",
    "print_prediction(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: street_music \n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_path='Sample Auido/Car_horn.wav'\n",
    "print_prediction(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: dog_bark \n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_path='Sample Auido/dog_bark.wav'\n",
    "print_prediction(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: drilling \n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_path='Sample Auido/drilling.wav'\n",
    "print_prediction(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: engine_idling \n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_path='Sample Auido/engine.wav'\n",
    "print_prediction(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
