{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Urban Sounds Classification using Deep Learning\n",
    "\n",
    "## Udacity-MLND\n",
    "\n",
    "### Single_Feature_MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting data from csv files into numpy arrays from Data Saved in 01 Data Visualisation and Preprocessing\n",
    "from numpy import genfromtxt\n",
    "x_train = genfromtxt('train_data.csv', delimiter=',')\n",
    "y_train = genfromtxt('train_labels.csv', delimiter=',')\n",
    "x_test = genfromtxt('test_data.csv', delimiter=',')\n",
    "y_test = genfromtxt('test_labels.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7895, 10), (837, 10))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#converting to one hot\n",
    "from keras.utils.np_utils import to_categorical\n",
    "y_train = to_categorical(y_train, num_classes=10)\n",
    "y_test = to_categorical(y_test, num_classes=10)\n",
    "y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense,Dropout,Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forming model\n",
    "model=Sequential()\n",
    "#building the model\n",
    "model.add(Dense(units=256,activation='relu',input_dim=40))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=256,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=256,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compiling\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7895 samples, validate on 837 samples\n",
      "Epoch 1/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.8269 - acc: 0.680 - ETA: 0s - loss: 0.8235 - acc: 0.696 - ETA: 0s - loss: 0.7893 - acc: 0.721 - ETA: 0s - loss: 0.8258 - acc: 0.726 - ETA: 0s - loss: 0.8233 - acc: 0.731 - ETA: 0s - loss: 0.8384 - acc: 0.725 - ETA: 0s - loss: 0.8419 - acc: 0.720 - ETA: 0s - loss: 0.8361 - acc: 0.723 - ETA: 0s - loss: 0.8245 - acc: 0.727 - ETA: 0s - loss: 0.8328 - acc: 0.723 - ETA: 0s - loss: 0.8327 - acc: 0.721 - ETA: 0s - loss: 0.8269 - acc: 0.723 - ETA: 0s - loss: 0.8234 - acc: 0.724 - ETA: 0s - loss: 0.8229 - acc: 0.726 - ETA: 0s - loss: 0.8255 - acc: 0.727 - ETA: 0s - loss: 0.8235 - acc: 0.727 - ETA: 0s - loss: 0.8235 - acc: 0.726 - ETA: 0s - loss: 0.8163 - acc: 0.729 - ETA: 0s - loss: 0.8209 - acc: 0.730 - ETA: 0s - loss: 0.8169 - acc: 0.731 - 1s 140us/step - loss: 0.8136 - acc: 0.7317 - val_loss: 1.3506 - val_acc: 0.5711\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.35063, saving model to Saved_models/basic_mlp.hdf5\n",
      "Epoch 2/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.8235 - acc: 0.700 - ETA: 1s - loss: 0.8513 - acc: 0.737 - ETA: 1s - loss: 0.8115 - acc: 0.738 - ETA: 0s - loss: 0.8080 - acc: 0.740 - ETA: 0s - loss: 0.7993 - acc: 0.745 - ETA: 0s - loss: 0.7694 - acc: 0.751 - ETA: 0s - loss: 0.7717 - acc: 0.752 - ETA: 0s - loss: 0.7752 - acc: 0.752 - ETA: 0s - loss: 0.7635 - acc: 0.754 - ETA: 0s - loss: 0.7630 - acc: 0.754 - ETA: 0s - loss: 0.7626 - acc: 0.752 - ETA: 0s - loss: 0.7705 - acc: 0.750 - ETA: 0s - loss: 0.7657 - acc: 0.752 - ETA: 0s - loss: 0.7731 - acc: 0.750 - ETA: 0s - loss: 0.7729 - acc: 0.749 - ETA: 0s - loss: 0.7761 - acc: 0.748 - ETA: 0s - loss: 0.7719 - acc: 0.749 - ETA: 0s - loss: 0.7742 - acc: 0.747 - ETA: 0s - loss: 0.7758 - acc: 0.747 - ETA: 0s - loss: 0.7782 - acc: 0.746 - 1s 141us/step - loss: 0.7789 - acc: 0.7457 - val_loss: 1.3114 - val_acc: 0.5866\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.35063 to 1.31138, saving model to Saved_models/basic_mlp.hdf5\n",
      "Epoch 3/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.8031 - acc: 0.720 - ETA: 0s - loss: 0.8343 - acc: 0.740 - ETA: 0s - loss: 0.8126 - acc: 0.732 - ETA: 0s - loss: 0.8226 - acc: 0.728 - ETA: 0s - loss: 0.7901 - acc: 0.735 - ETA: 0s - loss: 0.8016 - acc: 0.734 - ETA: 0s - loss: 0.8088 - acc: 0.731 - ETA: 0s - loss: 0.7932 - acc: 0.738 - ETA: 0s - loss: 0.7829 - acc: 0.744 - ETA: 0s - loss: 0.7892 - acc: 0.741 - ETA: 0s - loss: 0.7995 - acc: 0.738 - ETA: 0s - loss: 0.8054 - acc: 0.736 - ETA: 0s - loss: 0.7975 - acc: 0.739 - ETA: 0s - loss: 0.7883 - acc: 0.742 - ETA: 0s - loss: 0.7948 - acc: 0.741 - ETA: 0s - loss: 0.7965 - acc: 0.739 - ETA: 0s - loss: 0.7975 - acc: 0.739 - ETA: 0s - loss: 0.7968 - acc: 0.740 - ETA: 0s - loss: 0.7911 - acc: 0.741 - ETA: 0s - loss: 0.7828 - acc: 0.743 - 1s 135us/step - loss: 0.7812 - acc: 0.7431 - val_loss: 1.2979 - val_acc: 0.6057\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.31138 to 1.29786, saving model to Saved_models/basic_mlp.hdf5\n",
      "Epoch 4/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.4407 - acc: 0.860 - ETA: 1s - loss: 0.8149 - acc: 0.742 - ETA: 1s - loss: 0.8011 - acc: 0.753 - ETA: 1s - loss: 0.8117 - acc: 0.747 - ETA: 0s - loss: 0.8119 - acc: 0.742 - ETA: 0s - loss: 0.8109 - acc: 0.738 - ETA: 0s - loss: 0.7806 - acc: 0.745 - ETA: 0s - loss: 0.7751 - acc: 0.746 - ETA: 0s - loss: 0.7623 - acc: 0.750 - ETA: 0s - loss: 0.7690 - acc: 0.746 - ETA: 0s - loss: 0.7666 - acc: 0.746 - ETA: 0s - loss: 0.7534 - acc: 0.751 - ETA: 0s - loss: 0.7471 - acc: 0.754 - ETA: 0s - loss: 0.7523 - acc: 0.752 - ETA: 0s - loss: 0.7533 - acc: 0.751 - ETA: 0s - loss: 0.7524 - acc: 0.750 - ETA: 0s - loss: 0.7513 - acc: 0.749 - ETA: 0s - loss: 0.7546 - acc: 0.748 - ETA: 0s - loss: 0.7585 - acc: 0.747 - ETA: 0s - loss: 0.7579 - acc: 0.748 - ETA: 0s - loss: 0.7554 - acc: 0.749 - ETA: 0s - loss: 0.7526 - acc: 0.750 - ETA: 0s - loss: 0.7537 - acc: 0.750 - ETA: 0s - loss: 0.7569 - acc: 0.750 - 1s 165us/step - loss: 0.7571 - acc: 0.7497 - val_loss: 1.2916 - val_acc: 0.6153\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.29786 to 1.29163, saving model to Saved_models/basic_mlp.hdf5\n",
      "Epoch 5/50\n",
      "7895/7895 [==============================] - ETA: 0s - loss: 1.0128 - acc: 0.680 - ETA: 1s - loss: 0.7862 - acc: 0.756 - ETA: 1s - loss: 0.8294 - acc: 0.741 - ETA: 1s - loss: 0.7747 - acc: 0.750 - ETA: 0s - loss: 0.7647 - acc: 0.747 - ETA: 0s - loss: 0.7351 - acc: 0.752 - ETA: 0s - loss: 0.7389 - acc: 0.750 - ETA: 0s - loss: 0.7417 - acc: 0.748 - ETA: 0s - loss: 0.7528 - acc: 0.747 - ETA: 0s - loss: 0.7488 - acc: 0.749 - ETA: 0s - loss: 0.7413 - acc: 0.753 - ETA: 0s - loss: 0.7537 - acc: 0.752 - ETA: 0s - loss: 0.7602 - acc: 0.753 - ETA: 0s - loss: 0.7694 - acc: 0.751 - ETA: 0s - loss: 0.7718 - acc: 0.750 - ETA: 0s - loss: 0.7710 - acc: 0.750 - ETA: 0s - loss: 0.7669 - acc: 0.750 - ETA: 0s - loss: 0.7657 - acc: 0.751 - ETA: 0s - loss: 0.7644 - acc: 0.751 - ETA: 0s - loss: 0.7660 - acc: 0.750 - ETA: 0s - loss: 0.7669 - acc: 0.752 - ETA: 0s - loss: 0.7709 - acc: 0.751 - ETA: 0s - loss: 0.7706 - acc: 0.750 - 1s 161us/step - loss: 0.7703 - acc: 0.7493 - val_loss: 1.3228 - val_acc: 0.6022\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.29163\n",
      "Epoch 6/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.5703 - acc: 0.860 - ETA: 1s - loss: 0.6831 - acc: 0.794 - ETA: 1s - loss: 0.6761 - acc: 0.776 - ETA: 1s - loss: 0.7193 - acc: 0.757 - ETA: 1s - loss: 0.7509 - acc: 0.751 - ETA: 1s - loss: 0.7365 - acc: 0.755 - ETA: 0s - loss: 0.7200 - acc: 0.759 - ETA: 0s - loss: 0.7434 - acc: 0.756 - ETA: 0s - loss: 0.7442 - acc: 0.757 - ETA: 0s - loss: 0.7491 - acc: 0.756 - ETA: 0s - loss: 0.7489 - acc: 0.754 - ETA: 0s - loss: 0.7492 - acc: 0.753 - ETA: 0s - loss: 0.7472 - acc: 0.754 - ETA: 0s - loss: 0.7496 - acc: 0.753 - ETA: 0s - loss: 0.7474 - acc: 0.754 - ETA: 0s - loss: 0.7458 - acc: 0.753 - ETA: 0s - loss: 0.7505 - acc: 0.753 - ETA: 0s - loss: 0.7472 - acc: 0.753 - ETA: 0s - loss: 0.7478 - acc: 0.753 - ETA: 0s - loss: 0.7547 - acc: 0.750 - ETA: 0s - loss: 0.7499 - acc: 0.752 - ETA: 0s - loss: 0.7489 - acc: 0.752 - ETA: 0s - loss: 0.7473 - acc: 0.754 - ETA: 0s - loss: 0.7500 - acc: 0.753 - 1s 166us/step - loss: 0.7489 - acc: 0.7531 - val_loss: 1.3709 - val_acc: 0.5711\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.29163\n",
      "Epoch 7/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.5714 - acc: 0.820 - ETA: 0s - loss: 0.7178 - acc: 0.762 - ETA: 0s - loss: 0.7417 - acc: 0.747 - ETA: 0s - loss: 0.7389 - acc: 0.743 - ETA: 0s - loss: 0.7252 - acc: 0.754 - ETA: 0s - loss: 0.7410 - acc: 0.756 - ETA: 0s - loss: 0.7466 - acc: 0.753 - ETA: 0s - loss: 0.7343 - acc: 0.757 - ETA: 0s - loss: 0.7331 - acc: 0.758 - ETA: 0s - loss: 0.7301 - acc: 0.757 - ETA: 0s - loss: 0.7461 - acc: 0.751 - ETA: 0s - loss: 0.7478 - acc: 0.752 - ETA: 0s - loss: 0.7462 - acc: 0.752 - ETA: 0s - loss: 0.7465 - acc: 0.753 - ETA: 0s - loss: 0.7472 - acc: 0.752 - ETA: 0s - loss: 0.7408 - acc: 0.754 - ETA: 0s - loss: 0.7381 - acc: 0.755 - ETA: 0s - loss: 0.7386 - acc: 0.757 - ETA: 0s - loss: 0.7394 - acc: 0.757 - ETA: 0s - loss: 0.7407 - acc: 0.757 - ETA: 0s - loss: 0.7422 - acc: 0.757 - ETA: 0s - loss: 0.7401 - acc: 0.757 - ETA: 0s - loss: 0.7401 - acc: 0.757 - 1s 163us/step - loss: 0.7419 - acc: 0.7567 - val_loss: 1.2697 - val_acc: 0.5998\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.29163 to 1.26970, saving model to Saved_models/basic_mlp.hdf5\n",
      "Epoch 8/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.6268 - acc: 0.760 - ETA: 1s - loss: 0.6287 - acc: 0.760 - ETA: 1s - loss: 0.6546 - acc: 0.763 - ETA: 1s - loss: 0.6242 - acc: 0.774 - ETA: 1s - loss: 0.6414 - acc: 0.767 - ETA: 0s - loss: 0.6623 - acc: 0.762 - ETA: 0s - loss: 0.6804 - acc: 0.759 - ETA: 0s - loss: 0.6717 - acc: 0.764 - ETA: 0s - loss: 0.6843 - acc: 0.765 - ETA: 0s - loss: 0.6925 - acc: 0.763 - ETA: 0s - loss: 0.6914 - acc: 0.765 - ETA: 0s - loss: 0.6904 - acc: 0.766 - ETA: 0s - loss: 0.6916 - acc: 0.766 - ETA: 0s - loss: 0.7031 - acc: 0.765 - ETA: 0s - loss: 0.7125 - acc: 0.762 - ETA: 0s - loss: 0.7148 - acc: 0.760 - ETA: 0s - loss: 0.7114 - acc: 0.762 - ETA: 0s - loss: 0.7084 - acc: 0.763 - ETA: 0s - loss: 0.7138 - acc: 0.762 - ETA: 0s - loss: 0.7152 - acc: 0.761 - ETA: 0s - loss: 0.7165 - acc: 0.761 - ETA: 0s - loss: 0.7150 - acc: 0.762 - 1s 149us/step - loss: 0.7165 - acc: 0.7624 - val_loss: 1.2696 - val_acc: 0.5842\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.26970 to 1.26962, saving model to Saved_models/basic_mlp.hdf5\n",
      "Epoch 9/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.5240 - acc: 0.820 - ETA: 1s - loss: 0.7105 - acc: 0.771 - ETA: 1s - loss: 0.7283 - acc: 0.751 - ETA: 1s - loss: 0.7225 - acc: 0.756 - ETA: 0s - loss: 0.7201 - acc: 0.762 - ETA: 0s - loss: 0.7279 - acc: 0.756 - ETA: 0s - loss: 0.7384 - acc: 0.756 - ETA: 0s - loss: 0.7447 - acc: 0.758 - ETA: 0s - loss: 0.7428 - acc: 0.756 - ETA: 0s - loss: 0.7327 - acc: 0.759 - ETA: 0s - loss: 0.7359 - acc: 0.759 - ETA: 0s - loss: 0.7294 - acc: 0.762 - ETA: 0s - loss: 0.7331 - acc: 0.760 - ETA: 0s - loss: 0.7317 - acc: 0.761 - ETA: 0s - loss: 0.7269 - acc: 0.763 - ETA: 0s - loss: 0.7299 - acc: 0.763 - ETA: 0s - loss: 0.7291 - acc: 0.763 - ETA: 0s - loss: 0.7250 - acc: 0.763 - ETA: 0s - loss: 0.7265 - acc: 0.762 - ETA: 0s - loss: 0.7378 - acc: 0.759 - ETA: 0s - loss: 0.7366 - acc: 0.758 - ETA: 0s - loss: 0.7354 - acc: 0.759 - ETA: 0s - loss: 0.7388 - acc: 0.757 - ETA: 0s - loss: 0.7422 - acc: 0.756 - 1s 163us/step - loss: 0.7405 - acc: 0.7563 - val_loss: 1.2970 - val_acc: 0.5795\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.26962\n",
      "Epoch 10/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.7812 - acc: 0.720 - ETA: 1s - loss: 0.7379 - acc: 0.735 - ETA: 1s - loss: 0.7106 - acc: 0.742 - ETA: 1s - loss: 0.6686 - acc: 0.760 - ETA: 1s - loss: 0.6796 - acc: 0.757 - ETA: 1s - loss: 0.6975 - acc: 0.752 - ETA: 0s - loss: 0.7124 - acc: 0.754 - ETA: 0s - loss: 0.7172 - acc: 0.754 - ETA: 0s - loss: 0.7088 - acc: 0.757 - ETA: 0s - loss: 0.7189 - acc: 0.759 - ETA: 0s - loss: 0.7183 - acc: 0.761 - ETA: 0s - loss: 0.7223 - acc: 0.760 - ETA: 0s - loss: 0.7264 - acc: 0.759 - ETA: 0s - loss: 0.7284 - acc: 0.760 - ETA: 0s - loss: 0.7350 - acc: 0.757 - ETA: 0s - loss: 0.7273 - acc: 0.760 - ETA: 0s - loss: 0.7278 - acc: 0.758 - ETA: 0s - loss: 0.7278 - acc: 0.758 - ETA: 0s - loss: 0.7231 - acc: 0.759 - ETA: 0s - loss: 0.7199 - acc: 0.759 - ETA: 0s - loss: 0.7170 - acc: 0.762 - ETA: 0s - loss: 0.7149 - acc: 0.762 - 1s 152us/step - loss: 0.7151 - acc: 0.7630 - val_loss: 1.2920 - val_acc: 0.5950\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.26962\n",
      "Epoch 11/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.6854 - acc: 0.780 - ETA: 1s - loss: 0.6651 - acc: 0.786 - ETA: 0s - loss: 0.6466 - acc: 0.791 - ETA: 0s - loss: 0.6584 - acc: 0.782 - ETA: 0s - loss: 0.6663 - acc: 0.780 - ETA: 0s - loss: 0.6909 - acc: 0.771 - ETA: 0s - loss: 0.6965 - acc: 0.768 - ETA: 0s - loss: 0.7041 - acc: 0.770 - ETA: 0s - loss: 0.6956 - acc: 0.771 - ETA: 0s - loss: 0.6963 - acc: 0.772 - ETA: 0s - loss: 0.6834 - acc: 0.774 - ETA: 0s - loss: 0.6844 - acc: 0.774 - ETA: 0s - loss: 0.6848 - acc: 0.773 - ETA: 0s - loss: 0.6860 - acc: 0.774 - ETA: 0s - loss: 0.6881 - acc: 0.773 - ETA: 0s - loss: 0.6914 - acc: 0.771 - ETA: 0s - loss: 0.6924 - acc: 0.771 - ETA: 0s - loss: 0.6922 - acc: 0.770 - ETA: 0s - loss: 0.6956 - acc: 0.769 - ETA: 0s - loss: 0.7017 - acc: 0.767 - ETA: 0s - loss: 0.7021 - acc: 0.767 - 1s 147us/step - loss: 0.7038 - acc: 0.7691 - val_loss: 1.2999 - val_acc: 0.5830\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.26962\n",
      "Epoch 12/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.7042 - acc: 0.760 - ETA: 0s - loss: 0.6839 - acc: 0.791 - ETA: 1s - loss: 0.6883 - acc: 0.773 - ETA: 1s - loss: 0.7115 - acc: 0.767 - ETA: 1s - loss: 0.7069 - acc: 0.764 - ETA: 0s - loss: 0.7060 - acc: 0.769 - ETA: 0s - loss: 0.7016 - acc: 0.772 - ETA: 0s - loss: 0.6994 - acc: 0.771 - ETA: 0s - loss: 0.6938 - acc: 0.773 - ETA: 0s - loss: 0.7043 - acc: 0.769 - ETA: 0s - loss: 0.6915 - acc: 0.773 - ETA: 0s - loss: 0.6896 - acc: 0.775 - ETA: 0s - loss: 0.6856 - acc: 0.776 - ETA: 0s - loss: 0.6871 - acc: 0.775 - ETA: 0s - loss: 0.6925 - acc: 0.774 - ETA: 0s - loss: 0.6856 - acc: 0.777 - ETA: 0s - loss: 0.6979 - acc: 0.772 - ETA: 0s - loss: 0.6993 - acc: 0.770 - ETA: 0s - loss: 0.6980 - acc: 0.770 - ETA: 0s - loss: 0.6963 - acc: 0.770 - ETA: 0s - loss: 0.7034 - acc: 0.768 - ETA: 0s - loss: 0.7078 - acc: 0.767 - ETA: 0s - loss: 0.7123 - acc: 0.765 - 1s 159us/step - loss: 0.7121 - acc: 0.7644 - val_loss: 1.2573 - val_acc: 0.5890\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.26962 to 1.25725, saving model to Saved_models/basic_mlp.hdf5\n",
      "Epoch 13/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.6148 - acc: 0.780 - ETA: 1s - loss: 0.6820 - acc: 0.762 - ETA: 1s - loss: 0.6822 - acc: 0.781 - ETA: 1s - loss: 0.6882 - acc: 0.782 - ETA: 0s - loss: 0.6873 - acc: 0.785 - ETA: 0s - loss: 0.6930 - acc: 0.784 - ETA: 0s - loss: 0.7010 - acc: 0.781 - ETA: 0s - loss: 0.6984 - acc: 0.781 - ETA: 0s - loss: 0.6939 - acc: 0.781 - ETA: 0s - loss: 0.6974 - acc: 0.780 - ETA: 0s - loss: 0.6965 - acc: 0.780 - ETA: 0s - loss: 0.6910 - acc: 0.782 - ETA: 0s - loss: 0.6938 - acc: 0.779 - ETA: 0s - loss: 0.6916 - acc: 0.778 - ETA: 0s - loss: 0.6929 - acc: 0.777 - ETA: 0s - loss: 0.6842 - acc: 0.780 - ETA: 0s - loss: 0.6848 - acc: 0.780 - ETA: 0s - loss: 0.6865 - acc: 0.779 - ETA: 0s - loss: 0.6855 - acc: 0.779 - ETA: 0s - loss: 0.6937 - acc: 0.777 - 1s 135us/step - loss: 0.6958 - acc: 0.7767 - val_loss: 1.3192 - val_acc: 0.5938\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.25725\n",
      "Epoch 14/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.5640 - acc: 0.760 - ETA: 0s - loss: 0.6994 - acc: 0.758 - ETA: 0s - loss: 0.7167 - acc: 0.761 - ETA: 0s - loss: 0.7238 - acc: 0.761 - ETA: 0s - loss: 0.7118 - acc: 0.762 - ETA: 0s - loss: 0.6935 - acc: 0.770 - ETA: 0s - loss: 0.6748 - acc: 0.774 - ETA: 0s - loss: 0.6731 - acc: 0.776 - ETA: 0s - loss: 0.6775 - acc: 0.775 - ETA: 0s - loss: 0.6693 - acc: 0.777 - ETA: 0s - loss: 0.6726 - acc: 0.778 - ETA: 0s - loss: 0.6858 - acc: 0.774 - ETA: 0s - loss: 0.6844 - acc: 0.777 - ETA: 0s - loss: 0.6894 - acc: 0.775 - ETA: 0s - loss: 0.6900 - acc: 0.775 - ETA: 0s - loss: 0.6927 - acc: 0.773 - ETA: 0s - loss: 0.6857 - acc: 0.776 - ETA: 0s - loss: 0.6840 - acc: 0.775 - ETA: 0s - loss: 0.6818 - acc: 0.776 - ETA: 0s - loss: 0.6814 - acc: 0.775 - 1s 135us/step - loss: 0.6840 - acc: 0.7757 - val_loss: 1.3072 - val_acc: 0.5687\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.25725\n",
      "Epoch 15/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.3958 - acc: 0.840 - ETA: 1s - loss: 0.6211 - acc: 0.795 - ETA: 0s - loss: 0.6307 - acc: 0.798 - ETA: 0s - loss: 0.6277 - acc: 0.798 - ETA: 0s - loss: 0.6275 - acc: 0.799 - ETA: 0s - loss: 0.6276 - acc: 0.798 - ETA: 0s - loss: 0.6509 - acc: 0.787 - ETA: 0s - loss: 0.6679 - acc: 0.781 - ETA: 0s - loss: 0.6586 - acc: 0.782 - ETA: 0s - loss: 0.6673 - acc: 0.778 - ETA: 0s - loss: 0.6745 - acc: 0.777 - ETA: 0s - loss: 0.6705 - acc: 0.778 - ETA: 0s - loss: 0.6720 - acc: 0.778 - ETA: 0s - loss: 0.6736 - acc: 0.779 - ETA: 0s - loss: 0.6758 - acc: 0.777 - ETA: 0s - loss: 0.6762 - acc: 0.777 - ETA: 0s - loss: 0.6705 - acc: 0.779 - ETA: 0s - loss: 0.6690 - acc: 0.780 - ETA: 0s - loss: 0.6651 - acc: 0.781 - 1s 129us/step - loss: 0.6666 - acc: 0.7800 - val_loss: 1.3474 - val_acc: 0.5866\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.25725\n",
      "Epoch 16/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7895/7895 [==============================] - ETA: 1s - loss: 0.5673 - acc: 0.820 - ETA: 0s - loss: 0.5719 - acc: 0.810 - ETA: 0s - loss: 0.6126 - acc: 0.791 - ETA: 0s - loss: 0.6051 - acc: 0.787 - ETA: 0s - loss: 0.6216 - acc: 0.785 - ETA: 0s - loss: 0.6424 - acc: 0.781 - ETA: 0s - loss: 0.6518 - acc: 0.780 - ETA: 0s - loss: 0.6607 - acc: 0.777 - ETA: 0s - loss: 0.6624 - acc: 0.776 - ETA: 0s - loss: 0.6566 - acc: 0.778 - ETA: 0s - loss: 0.6640 - acc: 0.779 - ETA: 0s - loss: 0.6773 - acc: 0.775 - ETA: 0s - loss: 0.6789 - acc: 0.776 - ETA: 0s - loss: 0.6785 - acc: 0.775 - ETA: 0s - loss: 0.6789 - acc: 0.775 - ETA: 0s - loss: 0.6819 - acc: 0.773 - ETA: 0s - loss: 0.6789 - acc: 0.774 - ETA: 0s - loss: 0.6743 - acc: 0.776 - ETA: 0s - loss: 0.6726 - acc: 0.777 - ETA: 0s - loss: 0.6723 - acc: 0.778 - 1s 138us/step - loss: 0.6691 - acc: 0.7791 - val_loss: 1.2952 - val_acc: 0.6129\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.25725\n",
      "Epoch 17/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.6586 - acc: 0.780 - ETA: 1s - loss: 0.7376 - acc: 0.775 - ETA: 1s - loss: 0.6733 - acc: 0.788 - ETA: 0s - loss: 0.6930 - acc: 0.786 - ETA: 0s - loss: 0.6704 - acc: 0.785 - ETA: 0s - loss: 0.6824 - acc: 0.774 - ETA: 0s - loss: 0.6826 - acc: 0.778 - ETA: 0s - loss: 0.6653 - acc: 0.784 - ETA: 0s - loss: 0.6647 - acc: 0.782 - ETA: 0s - loss: 0.6870 - acc: 0.777 - ETA: 0s - loss: 0.6833 - acc: 0.777 - ETA: 0s - loss: 0.6860 - acc: 0.774 - ETA: 0s - loss: 0.6808 - acc: 0.773 - ETA: 0s - loss: 0.6827 - acc: 0.773 - ETA: 0s - loss: 0.6780 - acc: 0.777 - ETA: 0s - loss: 0.6799 - acc: 0.777 - ETA: 0s - loss: 0.6794 - acc: 0.776 - ETA: 0s - loss: 0.6726 - acc: 0.778 - ETA: 0s - loss: 0.6722 - acc: 0.779 - ETA: 0s - loss: 0.6719 - acc: 0.779 - ETA: 0s - loss: 0.6756 - acc: 0.778 - ETA: 0s - loss: 0.6730 - acc: 0.778 - 1s 146us/step - loss: 0.6730 - acc: 0.7782 - val_loss: 1.2790 - val_acc: 0.6022\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.25725\n",
      "Epoch 18/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.4250 - acc: 0.940 - ETA: 0s - loss: 0.6984 - acc: 0.764 - ETA: 0s - loss: 0.6763 - acc: 0.767 - ETA: 0s - loss: 0.6767 - acc: 0.774 - ETA: 0s - loss: 0.6777 - acc: 0.775 - ETA: 0s - loss: 0.6748 - acc: 0.775 - ETA: 0s - loss: 0.6648 - acc: 0.780 - ETA: 0s - loss: 0.6654 - acc: 0.781 - ETA: 0s - loss: 0.6565 - acc: 0.783 - ETA: 0s - loss: 0.6622 - acc: 0.781 - ETA: 0s - loss: 0.6661 - acc: 0.778 - ETA: 0s - loss: 0.6597 - acc: 0.781 - ETA: 0s - loss: 0.6551 - acc: 0.782 - ETA: 0s - loss: 0.6470 - acc: 0.784 - ETA: 0s - loss: 0.6453 - acc: 0.785 - ETA: 0s - loss: 0.6475 - acc: 0.786 - ETA: 0s - loss: 0.6472 - acc: 0.786 - ETA: 0s - loss: 0.6500 - acc: 0.787 - ETA: 0s - loss: 0.6503 - acc: 0.787 - ETA: 0s - loss: 0.6479 - acc: 0.788 - ETA: 0s - loss: 0.6495 - acc: 0.788 - 1s 143us/step - loss: 0.6533 - acc: 0.7872 - val_loss: 1.3272 - val_acc: 0.5830\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.25725\n",
      "Epoch 19/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.6558 - acc: 0.800 - ETA: 0s - loss: 0.6215 - acc: 0.800 - ETA: 0s - loss: 0.7458 - acc: 0.757 - ETA: 0s - loss: 0.7174 - acc: 0.763 - ETA: 0s - loss: 0.7158 - acc: 0.762 - ETA: 0s - loss: 0.7007 - acc: 0.765 - ETA: 0s - loss: 0.6998 - acc: 0.766 - ETA: 0s - loss: 0.6951 - acc: 0.767 - ETA: 0s - loss: 0.6971 - acc: 0.768 - ETA: 0s - loss: 0.6986 - acc: 0.772 - ETA: 0s - loss: 0.6871 - acc: 0.776 - ETA: 0s - loss: 0.6844 - acc: 0.776 - ETA: 0s - loss: 0.6791 - acc: 0.777 - ETA: 0s - loss: 0.6765 - acc: 0.778 - ETA: 0s - loss: 0.6695 - acc: 0.781 - ETA: 0s - loss: 0.6694 - acc: 0.782 - ETA: 0s - loss: 0.6681 - acc: 0.782 - ETA: 0s - loss: 0.6689 - acc: 0.782 - ETA: 0s - loss: 0.6639 - acc: 0.782 - ETA: 0s - loss: 0.6640 - acc: 0.783 - 1s 135us/step - loss: 0.6637 - acc: 0.7828 - val_loss: 1.3164 - val_acc: 0.5938\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.25725\n",
      "Epoch 20/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.6438 - acc: 0.800 - ETA: 1s - loss: 0.5521 - acc: 0.808 - ETA: 1s - loss: 0.6081 - acc: 0.800 - ETA: 1s - loss: 0.5992 - acc: 0.802 - ETA: 1s - loss: 0.6345 - acc: 0.790 - ETA: 1s - loss: 0.6362 - acc: 0.786 - ETA: 1s - loss: 0.6174 - acc: 0.792 - ETA: 0s - loss: 0.6199 - acc: 0.794 - ETA: 0s - loss: 0.6250 - acc: 0.792 - ETA: 0s - loss: 0.6234 - acc: 0.792 - ETA: 0s - loss: 0.6224 - acc: 0.791 - ETA: 0s - loss: 0.6277 - acc: 0.789 - ETA: 0s - loss: 0.6294 - acc: 0.788 - ETA: 0s - loss: 0.6327 - acc: 0.788 - ETA: 0s - loss: 0.6421 - acc: 0.786 - ETA: 0s - loss: 0.6432 - acc: 0.784 - ETA: 0s - loss: 0.6473 - acc: 0.782 - ETA: 0s - loss: 0.6449 - acc: 0.782 - ETA: 0s - loss: 0.6423 - acc: 0.783 - ETA: 0s - loss: 0.6421 - acc: 0.783 - 1s 140us/step - loss: 0.6414 - acc: 0.7843 - val_loss: 1.3297 - val_acc: 0.5842\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.25725\n",
      "Epoch 21/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.5588 - acc: 0.840 - ETA: 0s - loss: 0.6638 - acc: 0.786 - ETA: 0s - loss: 0.6512 - acc: 0.786 - ETA: 0s - loss: 0.6605 - acc: 0.779 - ETA: 0s - loss: 0.6855 - acc: 0.770 - ETA: 0s - loss: 0.6606 - acc: 0.785 - ETA: 0s - loss: 0.6677 - acc: 0.782 - ETA: 0s - loss: 0.6738 - acc: 0.781 - ETA: 0s - loss: 0.6705 - acc: 0.779 - ETA: 0s - loss: 0.6824 - acc: 0.778 - ETA: 0s - loss: 0.6892 - acc: 0.778 - ETA: 0s - loss: 0.6933 - acc: 0.775 - ETA: 0s - loss: 0.6891 - acc: 0.775 - ETA: 0s - loss: 0.6824 - acc: 0.776 - ETA: 0s - loss: 0.6821 - acc: 0.776 - ETA: 0s - loss: 0.6759 - acc: 0.779 - ETA: 0s - loss: 0.6722 - acc: 0.780 - ETA: 0s - loss: 0.6648 - acc: 0.781 - ETA: 0s - loss: 0.6613 - acc: 0.781 - ETA: 0s - loss: 0.6565 - acc: 0.783 - 1s 137us/step - loss: 0.6556 - acc: 0.7847 - val_loss: 1.3095 - val_acc: 0.6057\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.25725\n",
      "Epoch 22/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.6458 - acc: 0.780 - ETA: 1s - loss: 0.6373 - acc: 0.793 - ETA: 1s - loss: 0.5984 - acc: 0.801 - ETA: 0s - loss: 0.6098 - acc: 0.795 - ETA: 0s - loss: 0.6134 - acc: 0.796 - ETA: 0s - loss: 0.6044 - acc: 0.798 - ETA: 0s - loss: 0.6020 - acc: 0.800 - ETA: 0s - loss: 0.5993 - acc: 0.801 - ETA: 0s - loss: 0.5989 - acc: 0.800 - ETA: 0s - loss: 0.6098 - acc: 0.799 - ETA: 0s - loss: 0.6100 - acc: 0.798 - ETA: 0s - loss: 0.6106 - acc: 0.796 - ETA: 0s - loss: 0.6103 - acc: 0.798 - ETA: 0s - loss: 0.6082 - acc: 0.798 - ETA: 0s - loss: 0.6073 - acc: 0.799 - ETA: 0s - loss: 0.6098 - acc: 0.799 - ETA: 0s - loss: 0.6110 - acc: 0.798 - ETA: 0s - loss: 0.6187 - acc: 0.795 - ETA: 0s - loss: 0.6225 - acc: 0.795 - ETA: 0s - loss: 0.6238 - acc: 0.794 - 1s 138us/step - loss: 0.6279 - acc: 0.7934 - val_loss: 1.3910 - val_acc: 0.5962\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.25725\n",
      "Epoch 23/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.6826 - acc: 0.820 - ETA: 0s - loss: 0.6351 - acc: 0.802 - ETA: 0s - loss: 0.6328 - acc: 0.795 - ETA: 0s - loss: 0.6408 - acc: 0.793 - ETA: 0s - loss: 0.6256 - acc: 0.793 - ETA: 0s - loss: 0.6246 - acc: 0.787 - ETA: 0s - loss: 0.6414 - acc: 0.785 - ETA: 0s - loss: 0.6485 - acc: 0.785 - ETA: 0s - loss: 0.6411 - acc: 0.787 - ETA: 0s - loss: 0.6413 - acc: 0.786 - ETA: 0s - loss: 0.6410 - acc: 0.787 - ETA: 0s - loss: 0.6404 - acc: 0.789 - ETA: 0s - loss: 0.6424 - acc: 0.788 - ETA: 0s - loss: 0.6402 - acc: 0.789 - ETA: 0s - loss: 0.6407 - acc: 0.789 - ETA: 0s - loss: 0.6365 - acc: 0.789 - ETA: 0s - loss: 0.6395 - acc: 0.787 - ETA: 0s - loss: 0.6400 - acc: 0.786 - ETA: 0s - loss: 0.6411 - acc: 0.785 - 1s 128us/step - loss: 0.6379 - acc: 0.7871 - val_loss: 1.4195 - val_acc: 0.5962\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.25725\n",
      "Epoch 24/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.6301 - acc: 0.760 - ETA: 0s - loss: 0.5710 - acc: 0.802 - ETA: 0s - loss: 0.5674 - acc: 0.806 - ETA: 0s - loss: 0.5859 - acc: 0.795 - ETA: 0s - loss: 0.6055 - acc: 0.789 - ETA: 0s - loss: 0.6348 - acc: 0.791 - ETA: 0s - loss: 0.6310 - acc: 0.795 - ETA: 0s - loss: 0.6473 - acc: 0.791 - ETA: 0s - loss: 0.6456 - acc: 0.792 - ETA: 0s - loss: 0.6471 - acc: 0.790 - ETA: 0s - loss: 0.6445 - acc: 0.789 - ETA: 0s - loss: 0.6460 - acc: 0.789 - ETA: 0s - loss: 0.6369 - acc: 0.792 - ETA: 0s - loss: 0.6364 - acc: 0.794 - ETA: 0s - loss: 0.6352 - acc: 0.794 - ETA: 0s - loss: 0.6342 - acc: 0.795 - ETA: 0s - loss: 0.6382 - acc: 0.794 - ETA: 0s - loss: 0.6398 - acc: 0.793 - ETA: 0s - loss: 0.6387 - acc: 0.793 - ETA: 0s - loss: 0.6391 - acc: 0.793 - 1s 138us/step - loss: 0.6387 - acc: 0.7933 - val_loss: 1.3641 - val_acc: 0.5950\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.25725\n",
      "Epoch 25/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.7186 - acc: 0.780 - ETA: 1s - loss: 0.5294 - acc: 0.840 - ETA: 0s - loss: 0.5953 - acc: 0.813 - ETA: 0s - loss: 0.6054 - acc: 0.809 - ETA: 0s - loss: 0.6128 - acc: 0.802 - ETA: 0s - loss: 0.6103 - acc: 0.800 - ETA: 0s - loss: 0.6207 - acc: 0.800 - ETA: 0s - loss: 0.6295 - acc: 0.798 - ETA: 0s - loss: 0.6165 - acc: 0.800 - ETA: 0s - loss: 0.6109 - acc: 0.801 - ETA: 0s - loss: 0.6138 - acc: 0.799 - ETA: 0s - loss: 0.6137 - acc: 0.798 - ETA: 0s - loss: 0.6118 - acc: 0.801 - ETA: 0s - loss: 0.6069 - acc: 0.801 - ETA: 0s - loss: 0.6106 - acc: 0.800 - ETA: 0s - loss: 0.6192 - acc: 0.797 - ETA: 0s - loss: 0.6165 - acc: 0.796 - ETA: 0s - loss: 0.6183 - acc: 0.796 - ETA: 0s - loss: 0.6219 - acc: 0.795 - ETA: 0s - loss: 0.6223 - acc: 0.795 - 1s 137us/step - loss: 0.6173 - acc: 0.7967 - val_loss: 1.3896 - val_acc: 0.5986\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.25725\n",
      "Epoch 26/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.5313 - acc: 0.800 - ETA: 1s - loss: 0.6150 - acc: 0.784 - ETA: 0s - loss: 0.6106 - acc: 0.789 - ETA: 0s - loss: 0.6089 - acc: 0.792 - ETA: 0s - loss: 0.5947 - acc: 0.800 - ETA: 0s - loss: 0.5845 - acc: 0.806 - ETA: 0s - loss: 0.5875 - acc: 0.805 - ETA: 0s - loss: 0.5909 - acc: 0.803 - ETA: 0s - loss: 0.5997 - acc: 0.802 - ETA: 0s - loss: 0.6049 - acc: 0.801 - ETA: 0s - loss: 0.6037 - acc: 0.802 - ETA: 0s - loss: 0.6031 - acc: 0.803 - ETA: 0s - loss: 0.6042 - acc: 0.801 - ETA: 0s - loss: 0.6031 - acc: 0.799 - ETA: 0s - loss: 0.6036 - acc: 0.799 - ETA: 0s - loss: 0.6072 - acc: 0.797 - ETA: 0s - loss: 0.6060 - acc: 0.798 - ETA: 0s - loss: 0.6090 - acc: 0.796 - ETA: 0s - loss: 0.6124 - acc: 0.794 - ETA: 0s - loss: 0.6169 - acc: 0.793 - 1s 134us/step - loss: 0.6161 - acc: 0.7937 - val_loss: 1.3060 - val_acc: 0.6153\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.25725\n",
      "Epoch 27/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.8699 - acc: 0.660 - ETA: 1s - loss: 0.6442 - acc: 0.777 - ETA: 0s - loss: 0.6384 - acc: 0.784 - ETA: 0s - loss: 0.6254 - acc: 0.794 - ETA: 0s - loss: 0.5924 - acc: 0.805 - ETA: 0s - loss: 0.5909 - acc: 0.806 - ETA: 0s - loss: 0.5913 - acc: 0.808 - ETA: 0s - loss: 0.5926 - acc: 0.806 - ETA: 0s - loss: 0.5966 - acc: 0.804 - ETA: 0s - loss: 0.5968 - acc: 0.806 - ETA: 0s - loss: 0.5988 - acc: 0.805 - ETA: 0s - loss: 0.6010 - acc: 0.803 - ETA: 0s - loss: 0.5972 - acc: 0.803 - ETA: 0s - loss: 0.6010 - acc: 0.802 - ETA: 0s - loss: 0.6039 - acc: 0.802 - ETA: 0s - loss: 0.6030 - acc: 0.803 - ETA: 0s - loss: 0.6068 - acc: 0.802 - ETA: 0s - loss: 0.6060 - acc: 0.801 - ETA: 0s - loss: 0.6110 - acc: 0.800 - ETA: 0s - loss: 0.6105 - acc: 0.801 - 1s 135us/step - loss: 0.6130 - acc: 0.7999 - val_loss: 1.2808 - val_acc: 0.5711\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.25725\n",
      "Epoch 28/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.6411 - acc: 0.760 - ETA: 0s - loss: 0.5594 - acc: 0.820 - ETA: 0s - loss: 0.5947 - acc: 0.800 - ETA: 0s - loss: 0.5854 - acc: 0.800 - ETA: 0s - loss: 0.5652 - acc: 0.815 - ETA: 0s - loss: 0.5616 - acc: 0.817 - ETA: 0s - loss: 0.5603 - acc: 0.814 - ETA: 0s - loss: 0.5673 - acc: 0.814 - ETA: 0s - loss: 0.5608 - acc: 0.815 - ETA: 0s - loss: 0.5542 - acc: 0.818 - ETA: 0s - loss: 0.5584 - acc: 0.815 - ETA: 0s - loss: 0.5632 - acc: 0.814 - ETA: 0s - loss: 0.5662 - acc: 0.813 - ETA: 0s - loss: 0.5660 - acc: 0.814 - ETA: 0s - loss: 0.5752 - acc: 0.811 - ETA: 0s - loss: 0.5815 - acc: 0.807 - ETA: 0s - loss: 0.5888 - acc: 0.804 - ETA: 0s - loss: 0.5971 - acc: 0.801 - ETA: 0s - loss: 0.5974 - acc: 0.801 - ETA: 0s - loss: 0.5972 - acc: 0.802 - 1s 133us/step - loss: 0.5964 - acc: 0.8027 - val_loss: 1.3472 - val_acc: 0.6057\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.25725\n",
      "Epoch 29/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 1.1372 - acc: 0.740 - ETA: 1s - loss: 0.5804 - acc: 0.815 - ETA: 0s - loss: 0.5802 - acc: 0.805 - ETA: 0s - loss: 0.5826 - acc: 0.808 - ETA: 0s - loss: 0.5837 - acc: 0.813 - ETA: 0s - loss: 0.5841 - acc: 0.812 - ETA: 0s - loss: 0.5745 - acc: 0.810 - ETA: 0s - loss: 0.5908 - acc: 0.807 - ETA: 0s - loss: 0.5897 - acc: 0.807 - ETA: 0s - loss: 0.5878 - acc: 0.807 - ETA: 0s - loss: 0.5942 - acc: 0.805 - ETA: 0s - loss: 0.5908 - acc: 0.805 - ETA: 0s - loss: 0.5940 - acc: 0.802 - ETA: 0s - loss: 0.5913 - acc: 0.805 - ETA: 0s - loss: 0.5935 - acc: 0.804 - ETA: 0s - loss: 0.5984 - acc: 0.803 - ETA: 0s - loss: 0.5981 - acc: 0.804 - ETA: 0s - loss: 0.5981 - acc: 0.803 - ETA: 0s - loss: 0.6006 - acc: 0.803 - 1s 131us/step - loss: 0.5991 - acc: 0.8046 - val_loss: 1.2657 - val_acc: 0.6404\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.25725\n",
      "Epoch 30/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.4578 - acc: 0.780 - ETA: 1s - loss: 0.5396 - acc: 0.802 - ETA: 0s - loss: 0.5189 - acc: 0.811 - ETA: 0s - loss: 0.5362 - acc: 0.809 - ETA: 0s - loss: 0.5432 - acc: 0.811 - ETA: 0s - loss: 0.5520 - acc: 0.809 - ETA: 0s - loss: 0.5701 - acc: 0.803 - ETA: 0s - loss: 0.5739 - acc: 0.803 - ETA: 0s - loss: 0.5768 - acc: 0.801 - ETA: 0s - loss: 0.5743 - acc: 0.803 - ETA: 0s - loss: 0.5821 - acc: 0.804 - ETA: 0s - loss: 0.5817 - acc: 0.804 - ETA: 0s - loss: 0.5810 - acc: 0.801 - ETA: 0s - loss: 0.5876 - acc: 0.799 - ETA: 0s - loss: 0.5958 - acc: 0.796 - ETA: 0s - loss: 0.5971 - acc: 0.796 - ETA: 0s - loss: 0.5984 - acc: 0.797 - ETA: 0s - loss: 0.5919 - acc: 0.799 - ETA: 0s - loss: 0.5957 - acc: 0.798 - ETA: 0s - loss: 0.5922 - acc: 0.799 - 1s 134us/step - loss: 0.5922 - acc: 0.7994 - val_loss: 1.3515 - val_acc: 0.6153\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.25725\n",
      "Epoch 31/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.6772 - acc: 0.720 - ETA: 0s - loss: 0.5851 - acc: 0.798 - ETA: 0s - loss: 0.5660 - acc: 0.801 - ETA: 0s - loss: 0.5723 - acc: 0.797 - ETA: 0s - loss: 0.5729 - acc: 0.797 - ETA: 0s - loss: 0.5632 - acc: 0.803 - ETA: 0s - loss: 0.5664 - acc: 0.806 - ETA: 0s - loss: 0.5686 - acc: 0.808 - ETA: 0s - loss: 0.5741 - acc: 0.804 - ETA: 0s - loss: 0.5723 - acc: 0.802 - ETA: 0s - loss: 0.5805 - acc: 0.802 - ETA: 0s - loss: 0.5831 - acc: 0.800 - ETA: 0s - loss: 0.5854 - acc: 0.797 - ETA: 0s - loss: 0.5870 - acc: 0.797 - ETA: 0s - loss: 0.5915 - acc: 0.795 - ETA: 0s - loss: 0.5907 - acc: 0.797 - ETA: 0s - loss: 0.5876 - acc: 0.799 - ETA: 0s - loss: 0.5893 - acc: 0.800 - ETA: 0s - loss: 0.5917 - acc: 0.801 - 1s 128us/step - loss: 0.5946 - acc: 0.8008 - val_loss: 1.2904 - val_acc: 0.6153\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1.25725\n",
      "Epoch 32/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7895/7895 [==============================] - ETA: 1s - loss: 0.6468 - acc: 0.740 - ETA: 1s - loss: 0.6418 - acc: 0.791 - ETA: 0s - loss: 0.6052 - acc: 0.807 - ETA: 0s - loss: 0.5763 - acc: 0.809 - ETA: 0s - loss: 0.5753 - acc: 0.810 - ETA: 0s - loss: 0.5749 - acc: 0.807 - ETA: 0s - loss: 0.5808 - acc: 0.805 - ETA: 0s - loss: 0.5865 - acc: 0.806 - ETA: 0s - loss: 0.5847 - acc: 0.805 - ETA: 0s - loss: 0.5794 - acc: 0.807 - ETA: 0s - loss: 0.5808 - acc: 0.808 - ETA: 0s - loss: 0.5816 - acc: 0.806 - ETA: 0s - loss: 0.5888 - acc: 0.805 - ETA: 0s - loss: 0.5852 - acc: 0.806 - ETA: 0s - loss: 0.5872 - acc: 0.805 - ETA: 0s - loss: 0.5929 - acc: 0.804 - ETA: 0s - loss: 0.5938 - acc: 0.805 - ETA: 0s - loss: 0.5880 - acc: 0.807 - ETA: 0s - loss: 0.5967 - acc: 0.804 - 1s 130us/step - loss: 0.5926 - acc: 0.8060 - val_loss: 1.2758 - val_acc: 0.5950\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.25725\n",
      "Epoch 33/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.6362 - acc: 0.760 - ETA: 1s - loss: 0.6563 - acc: 0.786 - ETA: 1s - loss: 0.6512 - acc: 0.787 - ETA: 0s - loss: 0.6198 - acc: 0.799 - ETA: 0s - loss: 0.5936 - acc: 0.805 - ETA: 0s - loss: 0.5945 - acc: 0.805 - ETA: 0s - loss: 0.5782 - acc: 0.810 - ETA: 0s - loss: 0.5874 - acc: 0.804 - ETA: 0s - loss: 0.5929 - acc: 0.803 - ETA: 0s - loss: 0.5834 - acc: 0.804 - ETA: 0s - loss: 0.5836 - acc: 0.806 - ETA: 0s - loss: 0.5786 - acc: 0.806 - ETA: 0s - loss: 0.5627 - acc: 0.810 - ETA: 0s - loss: 0.5672 - acc: 0.809 - ETA: 0s - loss: 0.5632 - acc: 0.811 - ETA: 0s - loss: 0.5709 - acc: 0.810 - ETA: 0s - loss: 0.5699 - acc: 0.810 - ETA: 0s - loss: 0.5740 - acc: 0.808 - ETA: 0s - loss: 0.5822 - acc: 0.806 - ETA: 0s - loss: 0.5863 - acc: 0.805 - 1s 137us/step - loss: 0.5850 - acc: 0.8052 - val_loss: 1.3289 - val_acc: 0.6069\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.25725\n",
      "Epoch 34/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.9011 - acc: 0.760 - ETA: 1s - loss: 0.6103 - acc: 0.802 - ETA: 0s - loss: 0.6426 - acc: 0.796 - ETA: 0s - loss: 0.6468 - acc: 0.791 - ETA: 0s - loss: 0.6088 - acc: 0.802 - ETA: 0s - loss: 0.6095 - acc: 0.800 - ETA: 0s - loss: 0.6002 - acc: 0.803 - ETA: 0s - loss: 0.6121 - acc: 0.799 - ETA: 0s - loss: 0.6108 - acc: 0.800 - ETA: 0s - loss: 0.6067 - acc: 0.799 - ETA: 0s - loss: 0.6083 - acc: 0.801 - ETA: 0s - loss: 0.6040 - acc: 0.802 - ETA: 0s - loss: 0.6009 - acc: 0.803 - ETA: 0s - loss: 0.5972 - acc: 0.804 - ETA: 0s - loss: 0.5959 - acc: 0.804 - ETA: 0s - loss: 0.5977 - acc: 0.805 - ETA: 0s - loss: 0.5949 - acc: 0.806 - ETA: 0s - loss: 0.5984 - acc: 0.804 - ETA: 0s - loss: 0.5936 - acc: 0.806 - ETA: 0s - loss: 0.5898 - acc: 0.807 - 1s 133us/step - loss: 0.5907 - acc: 0.8068 - val_loss: 1.3117 - val_acc: 0.5890\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.25725\n",
      "Epoch 35/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.4338 - acc: 0.880 - ETA: 0s - loss: 0.5258 - acc: 0.814 - ETA: 0s - loss: 0.5552 - acc: 0.810 - ETA: 0s - loss: 0.5516 - acc: 0.817 - ETA: 0s - loss: 0.5744 - acc: 0.810 - ETA: 0s - loss: 0.5817 - acc: 0.809 - ETA: 0s - loss: 0.5917 - acc: 0.805 - ETA: 0s - loss: 0.5927 - acc: 0.806 - ETA: 0s - loss: 0.5981 - acc: 0.806 - ETA: 0s - loss: 0.5989 - acc: 0.803 - ETA: 0s - loss: 0.5967 - acc: 0.804 - ETA: 0s - loss: 0.5950 - acc: 0.803 - ETA: 0s - loss: 0.5925 - acc: 0.805 - ETA: 0s - loss: 0.5950 - acc: 0.803 - ETA: 0s - loss: 0.6034 - acc: 0.802 - ETA: 0s - loss: 0.6041 - acc: 0.802 - ETA: 0s - loss: 0.6028 - acc: 0.803 - ETA: 0s - loss: 0.6092 - acc: 0.801 - ETA: 0s - loss: 0.6058 - acc: 0.801 - ETA: 0s - loss: 0.6082 - acc: 0.799 - 1s 133us/step - loss: 0.6070 - acc: 0.8001 - val_loss: 1.3701 - val_acc: 0.6033\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1.25725\n",
      "Epoch 36/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.5306 - acc: 0.800 - ETA: 0s - loss: 0.5601 - acc: 0.833 - ETA: 0s - loss: 0.5850 - acc: 0.818 - ETA: 0s - loss: 0.6015 - acc: 0.804 - ETA: 0s - loss: 0.6170 - acc: 0.801 - ETA: 0s - loss: 0.5978 - acc: 0.808 - ETA: 0s - loss: 0.5860 - acc: 0.811 - ETA: 0s - loss: 0.5797 - acc: 0.811 - ETA: 0s - loss: 0.5775 - acc: 0.813 - ETA: 0s - loss: 0.5771 - acc: 0.813 - ETA: 0s - loss: 0.5782 - acc: 0.812 - ETA: 0s - loss: 0.5760 - acc: 0.814 - ETA: 0s - loss: 0.5716 - acc: 0.814 - ETA: 0s - loss: 0.5721 - acc: 0.813 - ETA: 0s - loss: 0.5731 - acc: 0.812 - ETA: 0s - loss: 0.5720 - acc: 0.813 - ETA: 0s - loss: 0.5777 - acc: 0.811 - ETA: 0s - loss: 0.5698 - acc: 0.813 - ETA: 0s - loss: 0.5719 - acc: 0.813 - ETA: 0s - loss: 0.5731 - acc: 0.814 - 1s 133us/step - loss: 0.5745 - acc: 0.8136 - val_loss: 1.3661 - val_acc: 0.5902\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1.25725\n",
      "Epoch 37/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.4297 - acc: 0.820 - ETA: 0s - loss: 0.6463 - acc: 0.788 - ETA: 0s - loss: 0.6528 - acc: 0.781 - ETA: 0s - loss: 0.6489 - acc: 0.780 - ETA: 0s - loss: 0.6217 - acc: 0.786 - ETA: 0s - loss: 0.6169 - acc: 0.792 - ETA: 0s - loss: 0.6097 - acc: 0.799 - ETA: 0s - loss: 0.5920 - acc: 0.803 - ETA: 0s - loss: 0.5955 - acc: 0.802 - ETA: 0s - loss: 0.5934 - acc: 0.805 - ETA: 0s - loss: 0.6006 - acc: 0.803 - ETA: 0s - loss: 0.6010 - acc: 0.803 - ETA: 0s - loss: 0.5998 - acc: 0.804 - ETA: 0s - loss: 0.5981 - acc: 0.803 - ETA: 0s - loss: 0.5963 - acc: 0.804 - ETA: 0s - loss: 0.5976 - acc: 0.803 - ETA: 0s - loss: 0.5977 - acc: 0.805 - ETA: 0s - loss: 0.5901 - acc: 0.807 - ETA: 0s - loss: 0.5938 - acc: 0.807 - 1s 131us/step - loss: 0.5919 - acc: 0.8087 - val_loss: 1.3405 - val_acc: 0.5783\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1.25725\n",
      "Epoch 38/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.5427 - acc: 0.800 - ETA: 1s - loss: 0.6440 - acc: 0.772 - ETA: 0s - loss: 0.6247 - acc: 0.781 - ETA: 0s - loss: 0.5968 - acc: 0.792 - ETA: 0s - loss: 0.5629 - acc: 0.810 - ETA: 0s - loss: 0.5606 - acc: 0.813 - ETA: 0s - loss: 0.5578 - acc: 0.812 - ETA: 0s - loss: 0.5526 - acc: 0.811 - ETA: 0s - loss: 0.5589 - acc: 0.811 - ETA: 0s - loss: 0.5610 - acc: 0.810 - ETA: 0s - loss: 0.5682 - acc: 0.807 - ETA: 0s - loss: 0.5713 - acc: 0.807 - ETA: 0s - loss: 0.5776 - acc: 0.808 - ETA: 0s - loss: 0.5794 - acc: 0.808 - ETA: 0s - loss: 0.5791 - acc: 0.809 - ETA: 0s - loss: 0.5835 - acc: 0.808 - ETA: 0s - loss: 0.5831 - acc: 0.806 - ETA: 0s - loss: 0.5894 - acc: 0.805 - ETA: 0s - loss: 0.5881 - acc: 0.804 - ETA: 0s - loss: 0.5875 - acc: 0.804 - 1s 134us/step - loss: 0.5868 - acc: 0.8051 - val_loss: 1.3200 - val_acc: 0.5854\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.25725\n",
      "Epoch 39/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.4961 - acc: 0.820 - ETA: 0s - loss: 0.6242 - acc: 0.792 - ETA: 0s - loss: 0.6325 - acc: 0.800 - ETA: 0s - loss: 0.6358 - acc: 0.796 - ETA: 0s - loss: 0.6057 - acc: 0.803 - ETA: 0s - loss: 0.5890 - acc: 0.810 - ETA: 0s - loss: 0.6013 - acc: 0.804 - ETA: 0s - loss: 0.6025 - acc: 0.805 - ETA: 0s - loss: 0.5981 - acc: 0.808 - ETA: 0s - loss: 0.5933 - acc: 0.809 - ETA: 0s - loss: 0.5947 - acc: 0.808 - ETA: 0s - loss: 0.5922 - acc: 0.809 - ETA: 0s - loss: 0.5940 - acc: 0.808 - ETA: 0s - loss: 0.5945 - acc: 0.808 - ETA: 0s - loss: 0.5860 - acc: 0.810 - ETA: 0s - loss: 0.5818 - acc: 0.810 - ETA: 0s - loss: 0.5813 - acc: 0.810 - ETA: 0s - loss: 0.5813 - acc: 0.809 - ETA: 0s - loss: 0.5799 - acc: 0.810 - 1s 133us/step - loss: 0.5821 - acc: 0.8096 - val_loss: 1.4097 - val_acc: 0.5914\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1.25725\n",
      "Epoch 40/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.4147 - acc: 0.900 - ETA: 0s - loss: 0.5741 - acc: 0.828 - ETA: 0s - loss: 0.5596 - acc: 0.828 - ETA: 0s - loss: 0.5695 - acc: 0.823 - ETA: 0s - loss: 0.5872 - acc: 0.814 - ETA: 0s - loss: 0.6004 - acc: 0.810 - ETA: 0s - loss: 0.5891 - acc: 0.813 - ETA: 0s - loss: 0.6021 - acc: 0.811 - ETA: 0s - loss: 0.5904 - acc: 0.813 - ETA: 0s - loss: 0.5869 - acc: 0.814 - ETA: 0s - loss: 0.5871 - acc: 0.813 - ETA: 0s - loss: 0.5799 - acc: 0.813 - ETA: 0s - loss: 0.5795 - acc: 0.813 - ETA: 0s - loss: 0.5861 - acc: 0.812 - ETA: 0s - loss: 0.5779 - acc: 0.814 - ETA: 0s - loss: 0.5810 - acc: 0.813 - ETA: 0s - loss: 0.5851 - acc: 0.812 - ETA: 0s - loss: 0.5861 - acc: 0.812 - ETA: 0s - loss: 0.5836 - acc: 0.811 - 1s 131us/step - loss: 0.5814 - acc: 0.8133 - val_loss: 1.4004 - val_acc: 0.5854\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.25725\n",
      "Epoch 41/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.5164 - acc: 0.840 - ETA: 1s - loss: 0.6093 - acc: 0.811 - ETA: 0s - loss: 0.6096 - acc: 0.823 - ETA: 0s - loss: 0.6013 - acc: 0.812 - ETA: 0s - loss: 0.5854 - acc: 0.816 - ETA: 0s - loss: 0.6082 - acc: 0.806 - ETA: 0s - loss: 0.5988 - acc: 0.807 - ETA: 0s - loss: 0.5917 - acc: 0.809 - ETA: 0s - loss: 0.5926 - acc: 0.808 - ETA: 0s - loss: 0.5974 - acc: 0.806 - ETA: 0s - loss: 0.5946 - acc: 0.806 - ETA: 0s - loss: 0.5949 - acc: 0.806 - ETA: 0s - loss: 0.5985 - acc: 0.804 - ETA: 0s - loss: 0.5895 - acc: 0.807 - ETA: 0s - loss: 0.5960 - acc: 0.806 - ETA: 0s - loss: 0.5932 - acc: 0.806 - ETA: 0s - loss: 0.6013 - acc: 0.803 - ETA: 0s - loss: 0.6021 - acc: 0.802 - ETA: 0s - loss: 0.6011 - acc: 0.803 - ETA: 0s - loss: 0.5965 - acc: 0.805 - 1s 134us/step - loss: 0.5951 - acc: 0.8061 - val_loss: 1.4190 - val_acc: 0.6081\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1.25725\n",
      "Epoch 42/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.4453 - acc: 0.840 - ETA: 0s - loss: 0.5156 - acc: 0.826 - ETA: 0s - loss: 0.6150 - acc: 0.791 - ETA: 0s - loss: 0.5567 - acc: 0.814 - ETA: 0s - loss: 0.5468 - acc: 0.818 - ETA: 0s - loss: 0.5401 - acc: 0.818 - ETA: 0s - loss: 0.5458 - acc: 0.814 - ETA: 0s - loss: 0.5584 - acc: 0.811 - ETA: 0s - loss: 0.5488 - acc: 0.816 - ETA: 0s - loss: 0.5487 - acc: 0.815 - ETA: 0s - loss: 0.5495 - acc: 0.813 - ETA: 0s - loss: 0.5457 - acc: 0.814 - ETA: 0s - loss: 0.5470 - acc: 0.815 - ETA: 0s - loss: 0.5500 - acc: 0.814 - ETA: 0s - loss: 0.5478 - acc: 0.816 - ETA: 0s - loss: 0.5506 - acc: 0.815 - ETA: 0s - loss: 0.5535 - acc: 0.814 - ETA: 0s - loss: 0.5531 - acc: 0.814 - ETA: 0s - loss: 0.5527 - acc: 0.813 - ETA: 0s - loss: 0.5527 - acc: 0.813 - 1s 134us/step - loss: 0.5514 - acc: 0.8143 - val_loss: 1.4418 - val_acc: 0.5926\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.25725\n",
      "Epoch 43/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.3565 - acc: 0.860 - ETA: 1s - loss: 0.5115 - acc: 0.824 - ETA: 0s - loss: 0.4876 - acc: 0.840 - ETA: 0s - loss: 0.4835 - acc: 0.835 - ETA: 0s - loss: 0.5302 - acc: 0.819 - ETA: 0s - loss: 0.5438 - acc: 0.821 - ETA: 0s - loss: 0.5374 - acc: 0.822 - ETA: 0s - loss: 0.5336 - acc: 0.823 - ETA: 0s - loss: 0.5421 - acc: 0.821 - ETA: 0s - loss: 0.5413 - acc: 0.820 - ETA: 0s - loss: 0.5449 - acc: 0.819 - ETA: 0s - loss: 0.5566 - acc: 0.815 - ETA: 0s - loss: 0.5591 - acc: 0.814 - ETA: 0s - loss: 0.5603 - acc: 0.814 - ETA: 0s - loss: 0.5596 - acc: 0.814 - ETA: 0s - loss: 0.5601 - acc: 0.813 - ETA: 0s - loss: 0.5615 - acc: 0.815 - ETA: 0s - loss: 0.5641 - acc: 0.815 - ETA: 0s - loss: 0.5588 - acc: 0.816 - ETA: 0s - loss: 0.5591 - acc: 0.816 - 1s 136us/step - loss: 0.5580 - acc: 0.8171 - val_loss: 1.3753 - val_acc: 0.6057\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1.25725\n",
      "Epoch 44/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.8104 - acc: 0.740 - ETA: 0s - loss: 0.5860 - acc: 0.797 - ETA: 0s - loss: 0.6042 - acc: 0.800 - ETA: 0s - loss: 0.6025 - acc: 0.800 - ETA: 0s - loss: 0.5723 - acc: 0.812 - ETA: 0s - loss: 0.5894 - acc: 0.806 - ETA: 0s - loss: 0.5742 - acc: 0.813 - ETA: 0s - loss: 0.5767 - acc: 0.811 - ETA: 0s - loss: 0.5750 - acc: 0.812 - ETA: 0s - loss: 0.5773 - acc: 0.813 - ETA: 0s - loss: 0.5717 - acc: 0.815 - ETA: 0s - loss: 0.5732 - acc: 0.813 - ETA: 0s - loss: 0.5730 - acc: 0.813 - ETA: 0s - loss: 0.5783 - acc: 0.810 - ETA: 0s - loss: 0.5793 - acc: 0.810 - ETA: 0s - loss: 0.5726 - acc: 0.812 - ETA: 0s - loss: 0.5774 - acc: 0.812 - ETA: 0s - loss: 0.5797 - acc: 0.811 - ETA: 0s - loss: 0.5733 - acc: 0.814 - ETA: 0s - loss: 0.5753 - acc: 0.814 - 1s 138us/step - loss: 0.5725 - acc: 0.8160 - val_loss: 1.3942 - val_acc: 0.5926\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1.25725\n",
      "Epoch 45/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.7545 - acc: 0.720 - ETA: 0s - loss: 0.5555 - acc: 0.804 - ETA: 0s - loss: 0.5695 - acc: 0.809 - ETA: 0s - loss: 0.5485 - acc: 0.811 - ETA: 0s - loss: 0.5587 - acc: 0.815 - ETA: 0s - loss: 0.5404 - acc: 0.817 - ETA: 0s - loss: 0.5503 - acc: 0.815 - ETA: 0s - loss: 0.5421 - acc: 0.817 - ETA: 0s - loss: 0.5366 - acc: 0.820 - ETA: 0s - loss: 0.5395 - acc: 0.820 - ETA: 0s - loss: 0.5434 - acc: 0.820 - ETA: 0s - loss: 0.5402 - acc: 0.820 - ETA: 0s - loss: 0.5442 - acc: 0.818 - ETA: 0s - loss: 0.5481 - acc: 0.817 - ETA: 0s - loss: 0.5475 - acc: 0.817 - ETA: 0s - loss: 0.5502 - acc: 0.816 - ETA: 0s - loss: 0.5481 - acc: 0.818 - ETA: 0s - loss: 0.5495 - acc: 0.819 - ETA: 0s - loss: 0.5481 - acc: 0.819 - ETA: 0s - loss: 0.5492 - acc: 0.819 - ETA: 0s - loss: 0.5502 - acc: 0.818 - 1s 142us/step - loss: 0.5525 - acc: 0.8175 - val_loss: 1.4206 - val_acc: 0.5651\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1.25725\n",
      "Epoch 46/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.5754 - acc: 0.800 - ETA: 0s - loss: 0.5402 - acc: 0.822 - ETA: 0s - loss: 0.5774 - acc: 0.806 - ETA: 0s - loss: 0.5722 - acc: 0.813 - ETA: 0s - loss: 0.5734 - acc: 0.812 - ETA: 0s - loss: 0.5658 - acc: 0.816 - ETA: 0s - loss: 0.5714 - acc: 0.814 - ETA: 0s - loss: 0.5654 - acc: 0.816 - ETA: 0s - loss: 0.5619 - acc: 0.818 - ETA: 0s - loss: 0.5642 - acc: 0.815 - ETA: 0s - loss: 0.5626 - acc: 0.817 - ETA: 0s - loss: 0.5630 - acc: 0.817 - ETA: 0s - loss: 0.5661 - acc: 0.817 - ETA: 0s - loss: 0.5652 - acc: 0.815 - ETA: 0s - loss: 0.5682 - acc: 0.816 - ETA: 0s - loss: 0.5661 - acc: 0.816 - ETA: 0s - loss: 0.5671 - acc: 0.816 - ETA: 0s - loss: 0.5659 - acc: 0.816 - ETA: 0s - loss: 0.5690 - acc: 0.815 - ETA: 0s - loss: 0.5676 - acc: 0.815 - 1s 139us/step - loss: 0.5651 - acc: 0.8158 - val_loss: 1.3708 - val_acc: 0.6260\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1.25725\n",
      "Epoch 47/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.6470 - acc: 0.760 - ETA: 1s - loss: 0.5579 - acc: 0.815 - ETA: 0s - loss: 0.5744 - acc: 0.808 - ETA: 0s - loss: 0.5964 - acc: 0.807 - ETA: 0s - loss: 0.5777 - acc: 0.813 - ETA: 0s - loss: 0.5880 - acc: 0.811 - ETA: 0s - loss: 0.5998 - acc: 0.807 - ETA: 0s - loss: 0.5920 - acc: 0.809 - ETA: 0s - loss: 0.5819 - acc: 0.814 - ETA: 0s - loss: 0.5788 - acc: 0.811 - ETA: 0s - loss: 0.5728 - acc: 0.812 - ETA: 0s - loss: 0.5741 - acc: 0.811 - ETA: 0s - loss: 0.5716 - acc: 0.811 - ETA: 0s - loss: 0.5630 - acc: 0.813 - ETA: 0s - loss: 0.5658 - acc: 0.812 - ETA: 0s - loss: 0.5598 - acc: 0.814 - ETA: 0s - loss: 0.5593 - acc: 0.815 - ETA: 0s - loss: 0.5590 - acc: 0.814 - ETA: 0s - loss: 0.5560 - acc: 0.815 - ETA: 0s - loss: 0.5578 - acc: 0.815 - 1s 137us/step - loss: 0.5581 - acc: 0.8155 - val_loss: 1.4446 - val_acc: 0.6093\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1.25725\n",
      "Epoch 48/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7895/7895 [==============================] - ETA: 1s - loss: 0.7418 - acc: 0.820 - ETA: 0s - loss: 0.6551 - acc: 0.802 - ETA: 0s - loss: 0.6121 - acc: 0.805 - ETA: 0s - loss: 0.5758 - acc: 0.816 - ETA: 0s - loss: 0.5689 - acc: 0.821 - ETA: 0s - loss: 0.5576 - acc: 0.820 - ETA: 0s - loss: 0.5549 - acc: 0.816 - ETA: 0s - loss: 0.5500 - acc: 0.815 - ETA: 0s - loss: 0.5459 - acc: 0.815 - ETA: 0s - loss: 0.5429 - acc: 0.815 - ETA: 0s - loss: 0.5398 - acc: 0.815 - ETA: 0s - loss: 0.5386 - acc: 0.816 - ETA: 0s - loss: 0.5503 - acc: 0.812 - ETA: 0s - loss: 0.5507 - acc: 0.811 - ETA: 0s - loss: 0.5487 - acc: 0.813 - ETA: 0s - loss: 0.5519 - acc: 0.813 - ETA: 0s - loss: 0.5479 - acc: 0.815 - ETA: 0s - loss: 0.5463 - acc: 0.816 - ETA: 0s - loss: 0.5500 - acc: 0.815 - ETA: 0s - loss: 0.5527 - acc: 0.815 - 1s 138us/step - loss: 0.5500 - acc: 0.8162 - val_loss: 1.4294 - val_acc: 0.6093\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1.25725\n",
      "Epoch 49/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.5969 - acc: 0.720 - ETA: 1s - loss: 0.4721 - acc: 0.824 - ETA: 0s - loss: 0.4953 - acc: 0.820 - ETA: 0s - loss: 0.5057 - acc: 0.817 - ETA: 0s - loss: 0.4854 - acc: 0.828 - ETA: 0s - loss: 0.4961 - acc: 0.828 - ETA: 0s - loss: 0.4902 - acc: 0.831 - ETA: 0s - loss: 0.5201 - acc: 0.825 - ETA: 0s - loss: 0.5235 - acc: 0.827 - ETA: 0s - loss: 0.5248 - acc: 0.827 - ETA: 0s - loss: 0.5288 - acc: 0.825 - ETA: 0s - loss: 0.5325 - acc: 0.824 - ETA: 0s - loss: 0.5294 - acc: 0.825 - ETA: 0s - loss: 0.5344 - acc: 0.822 - ETA: 0s - loss: 0.5409 - acc: 0.821 - ETA: 0s - loss: 0.5420 - acc: 0.821 - ETA: 0s - loss: 0.5392 - acc: 0.821 - ETA: 0s - loss: 0.5384 - acc: 0.821 - ETA: 0s - loss: 0.5438 - acc: 0.819 - ETA: 0s - loss: 0.5529 - acc: 0.817 - 1s 138us/step - loss: 0.5541 - acc: 0.8166 - val_loss: 1.5047 - val_acc: 0.5795\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1.25725\n",
      "Epoch 50/50\n",
      "7895/7895 [==============================] - ETA: 1s - loss: 0.3921 - acc: 0.860 - ETA: 1s - loss: 0.5288 - acc: 0.822 - ETA: 0s - loss: 0.4864 - acc: 0.830 - ETA: 0s - loss: 0.5259 - acc: 0.817 - ETA: 0s - loss: 0.5480 - acc: 0.810 - ETA: 0s - loss: 0.5585 - acc: 0.807 - ETA: 0s - loss: 0.5562 - acc: 0.808 - ETA: 0s - loss: 0.5561 - acc: 0.810 - ETA: 0s - loss: 0.5491 - acc: 0.814 - ETA: 0s - loss: 0.5415 - acc: 0.816 - ETA: 0s - loss: 0.5345 - acc: 0.820 - ETA: 0s - loss: 0.5368 - acc: 0.820 - ETA: 0s - loss: 0.5322 - acc: 0.821 - ETA: 0s - loss: 0.5324 - acc: 0.820 - ETA: 0s - loss: 0.5275 - acc: 0.822 - ETA: 0s - loss: 0.5269 - acc: 0.824 - ETA: 0s - loss: 0.5219 - acc: 0.825 - ETA: 0s - loss: 0.5257 - acc: 0.825 - ETA: 0s - loss: 0.5289 - acc: 0.825 - ETA: 0s - loss: 0.5340 - acc: 0.823 - 1s 136us/step - loss: 0.5362 - acc: 0.8229 - val_loss: 1.4018 - val_acc: 0.5974\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1.25725\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28e6b008fd0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint \n",
    "#fitting\n",
    "model.fit(x_train,y_train,epochs=50,validation_data=(x_test,y_test),batch_size=50,callbacks=[ModelCheckpoint(filepath='Saved_models/basic_mlp.hdf5', verbose=1, save_best_only=True)], verbose=1)\n",
    "# Display model architecture summary \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 256)               10496     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 144,650\n",
      "Trainable params: 144,650\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "7895/7895 [==============================] - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 0s 46us/step\n",
      "837/837 [==============================] - ETA:  - 0s 40us/step\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "\n",
    "# Calculate training accuracy \n",
    "score_train = model.evaluate(x_train, y_train, verbose=1)\n",
    "score_test = model.evaluate(x_test, y_test, verbose=1)\n",
    "accuracy_train = 100*score_train[1]\n",
    "accuracy_test = 100*score_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 91.6909%\n",
      "Test accuracy: 59.7372%\n"
     ]
    }
   ],
   "source": [
    "print(\"Training accuracy: %.4f%%\" % accuracy_train)\n",
    "print(\"Test accuracy: %.4f%%\" % accuracy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(file_path):\n",
    "    audio,sample_rate=librosa.load(file_path)\n",
    "    mfccs = np.mean(librosa.feature.mfcc(audio, sample_rate, n_mfcc=40).T,axis=0)\n",
    "    mfccs=np.reshape(mfccs,(1,mfccs.shape[0]))\n",
    "    return mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the necessary Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from librosa import display\n",
    "import librosa\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "lencoder=LabelEncoder\n",
    "class_lable=[\"air_conditioner\",\"car_horn\",\"children_playing\",\"dog_bark\",\"drilling\",\"engine_idling\",\"gun_shot\",\"jackhammer\",\"siren\",\"street_music\"]\n",
    "def print_prediction(file_path):\n",
    "    features = extract_features(file_path)\n",
    "    predicted_vector = model.predict_classes(features)\n",
    "    predicted_class = class_lable[predicted_vector[0]] \n",
    "    print(\"The predicted class is:\", predicted_class, '\\n') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: dog_bark \n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_path='UrbanSound8K/audio/fold5/100032-3-0-0.wav'\n",
    "print_prediction(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: street_music \n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_path='UrbanSound8K/audio/fold7/101848-9-0-0.wav'\n",
    "print_prediction(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: dog_bark \n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_path='UrbanSound8K/audio/fold10/200460-6-1-0.wav'\n",
    "print_prediction(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has predicted the gun_shot as a dog bark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: street_music \n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_path='Sample Auido/Car_horn.wav'\n",
    "print_prediction(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: dog_bark \n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_path='Sample Auido/dog_bark.wav'\n",
    "print_prediction(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: drilling \n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_path='Sample Auido/drilling.wav'\n",
    "print_prediction(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: siren \n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_path='Sample Auido/siren.wav'\n",
    "print_prediction(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: street_music \n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_path='Sample Auido/street_music.wav'\n",
    "print_prediction(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: engine_idling \n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_path='Sample Auido/engine.wav'\n",
    "print_prediction(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
